{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "Tubes1D_13517050.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xUp7dSsYD8w",
        "colab_type": "text"
      },
      "source": [
        "# IF3270 Pembelajaran Mesin - Tugas Besar 1D\n",
        "## Anggota kelompok :\n",
        "1. T. Antra Oksidian Tafly / 13517020\n",
        "2. Christopher Billy S. / 13517050\n",
        "3. Abel Stanley / 13517068\n",
        "4. Ferdy Santoso / 13517116"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdh31MG4YD8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import MyC45\n",
        "import ExternalModel as em"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KNRTi_UYD83",
        "colab_type": "text"
      },
      "source": [
        "## I. Skema split train 90% dan test 10%, dan menampilkan kinerja serta confusion matrixnya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdYmFiPCYD84",
        "colab_type": "code",
        "outputId": "43124048-5567-43a3-e01f-5f3bf3eeb00a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from MultiLayerPerceptron import MultiLayerPerceptron\n",
        "from MyC45 import MyTree\n",
        "from MyC45 import handleContinuousAttribute\n",
        "from sklearn.utils import shuffle\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "def MLP(data, batch_size):\n",
        "\n",
        "    #data = load_iris()\n",
        "    # list1 = list(data.iloc[0,:-2])\n",
        "    # print(list1)\n",
        "    # target = list(data.iloc[0,4:])\n",
        "    # print(target)\n",
        "    mlp = MultiLayerPerceptron(_layers=1 , _bias=1, _inputs=4, _outputs=2, _learningRate=0.01, _maxIter=50)\n",
        "\n",
        "    for i in range(mlp.maxIter):\n",
        "        mlp.totalError = 0\n",
        "        data = shuffle(data)\n",
        "        #print(data.data[0])\n",
        "\n",
        "        for j in range(len(data)):\n",
        "            row = list(data.iloc[j,:-mlp.outputs])\n",
        "            target = list(data.iloc[j,mlp.inputs:])\n",
        "            mlp.estimate(row)\n",
        "            #mlp.estimate(data.data[j])\n",
        "            mlp.updateDeltaWeight(target)\n",
        "            if j % batch_size == 0:\n",
        "                mlp.updateWeight()\n",
        "                mlp.updateTotalError(target)\n",
        "                # print(\"at iteration \", i, \" error = \" + str(mlp.totalError))\n",
        "        if j % batch_size != 0:\n",
        "            mlp.updateWeight()\n",
        "            mlp.updateTotalError(target)\n",
        "            # print(\"at iteration \", i, \" error = \" + str(mlp.totalError))\n",
        "\n",
        "\n",
        "        if(mlp.totalError < 0.01):\n",
        "            break\n",
        "\n",
        "    return mlp\n",
        "\n",
        "dataMLP = pd.read_csv(\"irisMLP.csv\")\n",
        "training_data = dataMLP.sample(frac = 0.9)\n",
        "test_dataMLP = dataMLP.drop(training_data.index)\n",
        "mlp = MLP(training_data, 10)\n",
        "confusion_matrixMLP = np.zeros((3, 3))\n",
        "for i in range(len(test_dataMLP)):\n",
        "    test = list(test_dataMLP.iloc[i,:-mlp.outputs])\n",
        "    target = list(test_dataMLP.iloc[i,mlp.inputs:])\n",
        "    estimate = mlp.estimate(test)\n",
        "    # print(estimate)\n",
        "    for i in range(len(estimate)):\n",
        "        estimate[i] = round(estimate[i])\n",
        "    # print(estimate)\n",
        "    # print(target)\n",
        "    row = -1\n",
        "    if (target == [0, 0]):\n",
        "        row = 0\n",
        "    elif (target == [0, 1]):\n",
        "        row = 1\n",
        "    elif (target == [1, 1]):\n",
        "        row = 2\n",
        "    column = -1\n",
        "    if (estimate == [0, 0]):\n",
        "        column = 0\n",
        "    elif (estimate == [0, 1]):\n",
        "        column = 1\n",
        "    elif (estimate == [1, 1]):\n",
        "        column = 2\n",
        "    if (column >= 0 and row >= 0):\n",
        "        confusion_matrixMLP[row][column] += 1\n",
        "print(\"MLP confusion matrix:\")\n",
        "print(confusion_matrixMLP)\n",
        "\n",
        "# Penghitungan kinerja\n",
        "total = 0\n",
        "for i in range(len(confusion_matrixMLP)):\n",
        "    for j in range(len(confusion_matrixMLP[i])):\n",
        "        total+=confusion_matrixMLP[i][j]\n",
        "if (total!=0):\n",
        "    for i in range(len(confusion_matrixMLP)):\n",
        "        print(i)\n",
        "        p = 0\n",
        "        p_acc = 0\n",
        "        error_rate = 0\n",
        "        tp = confusion_matrixMLP[i][i]\n",
        "        print(\"tp=\" + str(tp))\n",
        "        fn = 0\n",
        "        fp = 0\n",
        "        for j in range(len(confusion_matrixMLP[i])):\n",
        "            p += confusion_matrixMLP[i][j]\n",
        "            p_acc += confusion_matrixMLP[j][i]\n",
        "            if (j!=i):\n",
        "                fn += confusion_matrixMLP[i][j]\n",
        "                fp += confusion_matrixMLP[j][i]\n",
        "        tn = total - (tp + fn + fp)\n",
        "        n = total-p\n",
        "        n_acc = total-p_acc\n",
        "        print(\"p=\" + str(p))\n",
        "        print(\"p_acc=\" + str(p_acc))\n",
        "        print(\"fn=\" + str(fn))\n",
        "        print(\"fp=\" + str(fp))\n",
        "        print(\"tn=\" + str(tn))\n",
        "        print(\"n=\" + str(n))\n",
        "        print(\"n_acc=\" + str(n_acc))\n",
        "\n",
        "        print('error rate ' + str(i) + \":\")\n",
        "        error_rate = float(fn+fp) / total\n",
        "        print(error_rate)\n",
        "\n",
        "        if (p!=0):\n",
        "            recall = float(tp)/p\n",
        "            print('tp-rate/recall/sensitivity ' + str(i) + \":\")\n",
        "            print(recall)\n",
        "\n",
        "        if (n!=0):\n",
        "            fp_rate = float(fp)/n\n",
        "            print('fp-rate ' + str(i) + \":\")\n",
        "            print(fp_rate)\n",
        "\n",
        "        if (n!=0):\n",
        "            specificity = float(tn)/n\n",
        "            print('specificity ' + str(i) + \":\")\n",
        "            print(specificity)\n",
        "\n",
        "        if (p_acc!=0):\n",
        "            precision = float(tp)/p_acc\n",
        "            print('precision ' + str(i) + \":\")\n",
        "            print(precision)\n",
        "\n",
        "        if (n!=0):\n",
        "            accuracy = float(tp + tn)/total\n",
        "            print('accuracy ' + str(i) + \":\")\n",
        "            print(accuracy)\n",
        "\n",
        "        if (precision+recall != 0):\n",
        "            f_measure = 2 * float(precision * recall) / (precision + recall)\n",
        "            print('F-measure ' + str(i) + \":\")\n",
        "            print(f_measure)\n",
        "\n",
        "        balanced_accuracy = float(recall + specificity) / 2\n",
        "        print('Balanced accuracy ' + str(i) + \":\")\n",
        "        print(balanced_accuracy)\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "dataDTL = pd.read_csv(\"irisDTL.csv\")\n",
        "dataDTL = handleContinuousAttribute(dataDTL)\n",
        "training_dataDTL = dataDTL.sample(frac = 0.9)\n",
        "test_dataDTL = dataDTL.drop(training_dataDTL.index)\n",
        "tree = MyTree(_targetAttribute = \"target\")\n",
        "tree.buildTreeInit(trainingSet=training_dataDTL)\n",
        "confusion_matrixDTL = np.zeros((3, 3))\n",
        "# tree.printTree()\n",
        "for i in range(len(test_dataDTL)):\n",
        "    test = test_dataDTL.iloc[i]\n",
        "    target = test[\"target\"]\n",
        "    test = test.to_dict()\n",
        "    for key in test:\n",
        "        test[key] = str(test[key])\n",
        "    # print(test)\n",
        "    estimate = tree.predict(test)\n",
        "    # print(estimate)\n",
        "    row = -1\n",
        "    row = int(target)\n",
        "    column = -1\n",
        "    column = int(estimate)\n",
        "    if (column >= 0 and row >= 0):\n",
        "        confusion_matrixDTL[row][column] += 1\n",
        "print(\"DTL confusion matrix:\")\n",
        "print(confusion_matrixDTL)\n",
        "\n",
        "# Penghitungan kinerja\n",
        "total = 0\n",
        "for i in range(len(confusion_matrixDTL)):\n",
        "    for j in range(len(confusion_matrixDTL[i])):\n",
        "        total+=confusion_matrixDTL[i][j]\n",
        "if (total!=0):\n",
        "    for i in range(len(confusion_matrixDTL)):\n",
        "        print(i)\n",
        "        p = 0\n",
        "        p_acc = 0\n",
        "        error_rate = 0\n",
        "        tp = confusion_matrixDTL[i][i]\n",
        "        print(\"tp=\" + str(tp))\n",
        "        fn = 0\n",
        "        fp = 0\n",
        "        for j in range(len(confusion_matrixDTL[i])):\n",
        "            p += confusion_matrixDTL[i][j]\n",
        "            p_acc += confusion_matrixDTL[j][i]\n",
        "            if (j!=i):\n",
        "                fn += confusion_matrixDTL[i][j]\n",
        "                fp += confusion_matrixDTL[j][i]\n",
        "        tn = total - (tp + fn + fp)\n",
        "        n = total-p\n",
        "        n_acc = total-p_acc\n",
        "        print(\"p=\" + str(p))\n",
        "        print(\"p_acc=\" + str(p_acc))\n",
        "        print(\"fn=\" + str(fn))\n",
        "        print(\"fp=\" + str(fp))\n",
        "        print(\"tn=\" + str(tn))\n",
        "        print(\"n=\" + str(n))\n",
        "        print(\"n_acc=\" + str(n_acc))\n",
        "\n",
        "        print('error rate ' + str(i) + \":\")\n",
        "        error_rate = float(fn+fp) / total\n",
        "        print(error_rate)\n",
        "\n",
        "        if (p!=0):\n",
        "            recall = float(tp)/p\n",
        "            print('tp-rate/recall/sensitivity ' + str(i) + \":\")\n",
        "            print(recall)\n",
        "\n",
        "        if (n!=0):\n",
        "            fp_rate = float(fp)/n\n",
        "            print('fp-rate ' + str(i) + \":\")\n",
        "            print(fp_rate)\n",
        "\n",
        "        if (n!=0):\n",
        "            specificity = float(tn)/n\n",
        "            print('specificity ' + str(i) + \":\")\n",
        "            print(specificity)\n",
        "\n",
        "        if (p_acc!=0):\n",
        "            precision = float(tp)/p_acc\n",
        "            print('precision ' + str(i) + \":\")\n",
        "            print(precision)\n",
        "\n",
        "        if (n!=0):\n",
        "            accuracy = float(tp + tn)/total\n",
        "            print('accuracy ' + str(i) + \":\")\n",
        "            print(accuracy)\n",
        "\n",
        "        if (precision+recall != 0):\n",
        "            f_measure = 2 * float(precision * recall) / (precision + recall)\n",
        "            print('F-measure ' + str(i) + \":\")\n",
        "            print(f_measure)\n",
        "\n",
        "        balanced_accuracy = float(recall + specificity) / 2\n",
        "        print('Balanced accuracy ' + str(i) + \":\")\n",
        "        print(balanced_accuracy)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP confusion matrix:\n",
            "[[2. 0. 0.]\n",
            " [0. 8. 0.]\n",
            " [0. 5. 0.]]\n",
            "0\n",
            "tp=2.0\n",
            "p=2.0\n",
            "p_acc=2.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=13.0\n",
            "n=13.0\n",
            "n_acc=13.0\n",
            "error rate 0:\n",
            "0.0\n",
            "tp-rate/recall/sensitivity 0:\n",
            "1.0\n",
            "fp-rate 0:\n",
            "0.0\n",
            "specificity 0:\n",
            "1.0\n",
            "precision 0:\n",
            "1.0\n",
            "accuracy 0:\n",
            "1.0\n",
            "F-measure 0:\n",
            "1.0\n",
            "Balanced accuracy 0:\n",
            "1.0\n",
            "1\n",
            "tp=8.0\n",
            "p=8.0\n",
            "p_acc=13.0\n",
            "fn=0.0\n",
            "fp=5.0\n",
            "tn=2.0\n",
            "n=7.0\n",
            "n_acc=2.0\n",
            "error rate 1:\n",
            "0.3333333333333333\n",
            "tp-rate/recall/sensitivity 1:\n",
            "1.0\n",
            "fp-rate 1:\n",
            "0.7142857142857143\n",
            "specificity 1:\n",
            "0.2857142857142857\n",
            "precision 1:\n",
            "0.6153846153846154\n",
            "accuracy 1:\n",
            "0.6666666666666666\n",
            "F-measure 1:\n",
            "0.761904761904762\n",
            "Balanced accuracy 1:\n",
            "0.6428571428571428\n",
            "2\n",
            "tp=0.0\n",
            "p=5.0\n",
            "p_acc=0.0\n",
            "fn=5.0\n",
            "fp=0.0\n",
            "tn=10.0\n",
            "n=10.0\n",
            "n_acc=15.0\n",
            "error rate 2:\n",
            "0.3333333333333333\n",
            "tp-rate/recall/sensitivity 2:\n",
            "0.0\n",
            "fp-rate 2:\n",
            "0.0\n",
            "specificity 2:\n",
            "1.0\n",
            "accuracy 2:\n",
            "0.6666666666666666\n",
            "F-measure 2:\n",
            "0.0\n",
            "Balanced accuracy 2:\n",
            "0.5\n",
            "Entropy not 0 but already ran out attributes\n",
            "Entropy not 0 but already ran out attributes\n",
            "Entropy not 0 but already ran out attributes\n",
            "DTL confusion matrix:\n",
            "[[7. 0. 0.]\n",
            " [1. 2. 0.]\n",
            " [0. 0. 5.]]\n",
            "0\n",
            "tp=7.0\n",
            "p=7.0\n",
            "p_acc=8.0\n",
            "fn=0.0\n",
            "fp=1.0\n",
            "tn=7.0\n",
            "n=8.0\n",
            "n_acc=7.0\n",
            "error rate 0:\n",
            "0.06666666666666667\n",
            "tp-rate/recall/sensitivity 0:\n",
            "1.0\n",
            "fp-rate 0:\n",
            "0.125\n",
            "specificity 0:\n",
            "0.875\n",
            "precision 0:\n",
            "0.875\n",
            "accuracy 0:\n",
            "0.9333333333333333\n",
            "F-measure 0:\n",
            "0.9333333333333333\n",
            "Balanced accuracy 0:\n",
            "0.9375\n",
            "1\n",
            "tp=2.0\n",
            "p=3.0\n",
            "p_acc=2.0\n",
            "fn=1.0\n",
            "fp=0.0\n",
            "tn=12.0\n",
            "n=12.0\n",
            "n_acc=13.0\n",
            "error rate 1:\n",
            "0.06666666666666667\n",
            "tp-rate/recall/sensitivity 1:\n",
            "0.6666666666666666\n",
            "fp-rate 1:\n",
            "0.0\n",
            "specificity 1:\n",
            "1.0\n",
            "precision 1:\n",
            "1.0\n",
            "accuracy 1:\n",
            "0.9333333333333333\n",
            "F-measure 1:\n",
            "0.8\n",
            "Balanced accuracy 1:\n",
            "0.8333333333333333\n",
            "2\n",
            "tp=5.0\n",
            "p=5.0\n",
            "p_acc=5.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=10.0\n",
            "n=10.0\n",
            "n_acc=10.0\n",
            "error rate 2:\n",
            "0.0\n",
            "tp-rate/recall/sensitivity 2:\n",
            "1.0\n",
            "fp-rate 2:\n",
            "0.0\n",
            "specificity 2:\n",
            "1.0\n",
            "precision 2:\n",
            "1.0\n",
            "accuracy 2:\n",
            "1.0\n",
            "F-measure 2:\n",
            "1.0\n",
            "Balanced accuracy 2:\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkdAtFTZYD89",
        "colab_type": "text"
      },
      "source": [
        "## II. Skema 10-fold cross validation, dan menampilkan kinerjanya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFYi9R7MYD8-",
        "colab_type": "code",
        "outputId": "8e74dfce-6d5f-4232-ebe7-a6bb22f1c4a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.datasets import load_iris\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "from MyC45 import MyTree, handleContinuousAttribute, resetThresholdDict, printThresholdDict\n",
        "from MultiLayerPerceptron import MultiLayerPerceptron\n",
        "#import MultiLayerPerceptron\n",
        "\n",
        "def kFold(nFold, # how many folds\n",
        "         dataset, # dataset to be kFold-ed\n",
        "         ):\n",
        "    split = len(dataset) // nFold\n",
        "    result = []\n",
        "    start_idx = 0\n",
        "    for i in range(nFold):\n",
        "        indices = list(range(0,start_idx)) + list(range(start_idx+split,len(dataset)))\n",
        "        train = dataset[indices]\n",
        "        test = dataset[start_idx:start_idx+split]\n",
        "        result.append( (train,test) ) # tuple of ( train dataset, test dataset)\n",
        "        start_idx += split\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "irisDataMLP = []\n",
        "with open('irisMLP.csv') as f:\n",
        "    freader = csv.reader(f, delimiter=',')\n",
        "    for row in freader:\n",
        "        irisDataMLP.append(row)\n",
        "irisDataMLP = np.array(irisDataMLP)\n",
        "\n",
        "# print(irisDataMLP)\n",
        "\n",
        "# kf = KFold(n_splits=10, shuffle=False, random_state=1)\n",
        "attrs=['attr1', 'attr2', 'attr3', 'attr4', 'target']\n",
        "\n",
        "nFold = 10\n",
        "MLPresult = kFold(nFold, irisDataMLP)\n",
        "\n",
        "# Evaluate for MLP:\n",
        "print(\"Evaluating MLP Model with k-fold: \")\n",
        "\n",
        "# totalScore = 0\n",
        "confusion_matrixMLP = np.zeros((3, 3))\n",
        "for train, test in MLPresult:\n",
        "    print(\"TRAIN: --------\")\n",
        "    with open ('dummy.csv', mode='w', newline=\"\") as f:\n",
        "        fwriter = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "        for row in train: # train dataset\n",
        "            fwriter.writerow(row)\n",
        "    # ANN:\n",
        "    data = pd.read_csv(\"dummy.csv\")\n",
        "    mlp2 = MultiLayerPerceptron(_layers=1 , _bias=1, _inputs=4, _outputs=2, _learningRate=0.01, _maxIter=50)\n",
        "    # MLP(32, data)\n",
        "\n",
        "    print(\"VALIDATION: --------\")\n",
        "    correct = 0\n",
        "    for row in test: # test dataset\n",
        "        values = []\n",
        "        for val, attr in zip(row[:-1], attrs[:-1]):\n",
        "            values.append(float(val))\n",
        "        # print(values)\n",
        "        estimate = mlp2.estimate(values)\n",
        "        estimate = [int(estimate[0]), int(estimate[1])]\n",
        "        target = [int(row[-2]), int(row[-1])]\n",
        "        print(estimate, \" vs \", target)\n",
        "        \n",
        "        row = -1\n",
        "        if (target == [0, 0]):\n",
        "            row = 0\n",
        "        elif (target == [0, 1]):\n",
        "            row = 1\n",
        "        elif (target == [1, 1]):\n",
        "            row = 2\n",
        "        column = -1\n",
        "        if (estimate == [0, 0]):\n",
        "            column = 0\n",
        "        elif (estimate == [0, 1]):\n",
        "            column = 1\n",
        "        elif (estimate == [1, 1]):\n",
        "            column = 2\n",
        "        if (column >= 0 and row >= 0):\n",
        "            confusion_matrixMLP[row][column] += 1\n",
        "        # threshold: 0.5\n",
        "#         if abs(prediction - float(row[-1])) < 0.5:\n",
        "#             confusionMatrix[]\n",
        "#             correct+=1\n",
        "\n",
        "    print(\"MLP confusion matrix:\")\n",
        "    print(confusion_matrixMLP)\n",
        "\n",
        "    # Penghitungan kinerja\n",
        "    total = 0\n",
        "    for i in range(len(confusion_matrixMLP)):\n",
        "        for j in range(len(confusion_matrixMLP[i])):\n",
        "            total+=confusion_matrixMLP[i][j]\n",
        "    if (total!=0):\n",
        "        for i in range(len(confusion_matrixMLP)):\n",
        "            print(i)\n",
        "            p = 0\n",
        "            p_acc = 0\n",
        "            error_rate = 0\n",
        "            tp = confusion_matrixMLP[i][i]\n",
        "            print(\"tp=\" + str(tp))\n",
        "            fn = 0\n",
        "            fp = 0\n",
        "            for j in range(len(confusion_matrixMLP[i])):\n",
        "                p += confusion_matrixMLP[i][j]\n",
        "                p_acc += confusion_matrixMLP[j][i]\n",
        "                if (j!=i):\n",
        "                    fn += confusion_matrixMLP[i][j]\n",
        "                    fp += confusion_matrixMLP[j][i]\n",
        "            tn = total - (tp + fn + fp)\n",
        "            n = total-p\n",
        "            n_acc = total-p_acc\n",
        "            print(\"p=\" + str(p))\n",
        "            print(\"p_acc=\" + str(p_acc))\n",
        "            print(\"fn=\" + str(fn))\n",
        "            print(\"fp=\" + str(fp))\n",
        "            print(\"tn=\" + str(tn))\n",
        "            print(\"n=\" + str(n))\n",
        "            print(\"n_acc=\" + str(n_acc))\n",
        "\n",
        "            print('error rate ' + str(i) + \":\")\n",
        "            error_rate = float(fn+fp) / total\n",
        "            print(error_rate)\n",
        "\n",
        "            if (p!=0):\n",
        "                recall = float(tp)/p\n",
        "                print('tp-rate/recall/sensitivity ' + str(i) + \":\")\n",
        "                print(recall)\n",
        "\n",
        "            if (n!=0):\n",
        "                fp_rate = float(fp)/n\n",
        "                print('fp-rate ' + str(i) + \":\")\n",
        "                print(fp_rate)\n",
        "\n",
        "            if (n!=0):\n",
        "                specificity = float(tn)/n\n",
        "                print('specificity ' + str(i) + \":\")\n",
        "                print(specificity)\n",
        "\n",
        "            if (p_acc!=0):\n",
        "                precision = float(tp)/p_acc\n",
        "                print('precision ' + str(i) + \":\")\n",
        "                print(precision)\n",
        "\n",
        "            if (n!=0):\n",
        "                accuracy = float(tp + tn)/total\n",
        "                print('accuracy ' + str(i) + \":\")\n",
        "                print(accuracy)\n",
        "\n",
        "            if (precision+recall != 0):\n",
        "                f_measure = 2 * float(precision * recall) / (precision + recall)\n",
        "                print('F-measure ' + str(i) + \":\")\n",
        "                print(f_measure)\n",
        "\n",
        "            balanced_accuracy = float(recall + specificity) / 2\n",
        "            print('Balanced accuracy ' + str(i) + \":\")\n",
        "            print(balanced_accuracy)\n",
        "\n",
        "#     print(\"correct:\", correct, \"out of \", len(test))\n",
        "#     totalScore += correct / float(len(test))\n",
        "\n",
        "    \n",
        "        \n",
        "# print(\"MLP Model total score:\", totalScore/nFold)\n",
        "\n",
        "# Evaluate for C45:\n",
        "irisData = []\n",
        "with open('iris.csv') as f:\n",
        "    freader = csv.reader(f, delimiter=',')\n",
        "    for row in freader:\n",
        "        irisData.append(row)\n",
        "irisData = np.array(irisData)\n",
        "\n",
        "C45result = kFold(nFold, irisData)\n",
        "# print(C45result)\n",
        "print(\"Evaluating C45 Model with k-fold: \")\n",
        "\n",
        "totalScore = 0\n",
        "# idx = 0\n",
        "for train, test in C45result:\n",
        "    # print(idx)\n",
        "    # idx+=1\n",
        "    print(\"TRAIN: --------\")\n",
        "    # trainn, testt = C45result[7]\n",
        "    with open ('dummy.csv', mode='w') as f:\n",
        "        fwriter = csv.writer(f)\n",
        "        for row in train:\n",
        "            fwriter.writerow(row)\n",
        "\n",
        "    data = pd.read_csv(\"dummy.csv\", header=None, names=attrs)\n",
        "    training_dataset = handleContinuousAttribute(data)\n",
        "    t2 = MyTree(_targetAttribute = 'target')\n",
        "    print(\"=================================================\")\n",
        "    t2.buildTreeInit(trainingSet = training_dataset)\n",
        "    t2.printTree()\n",
        "    print(\"=================================================\")\n",
        "\n",
        "    print(\"VALIDATION: --------\")\n",
        "    #print(irisData[test])\n",
        "    correct = 0\n",
        "    for row in test:\n",
        "        values = {}\n",
        "        for val, attr in zip(row[:-1], attrs[:-1]):\n",
        "            values[attr] = float(val)\n",
        "        # print(values)\n",
        "        prediction = t.predict(values)\n",
        "        print(prediction, \" vs \", row[-1])\n",
        "        if prediction == row[-1]:\n",
        "            correct+=1\n",
        "    print(\"correct:\", correct, \"out of \", len(test))\n",
        "    totalScore += correct / float(len(test))\n",
        "    # reset threshold dict:\n",
        "    resetThresholdDict()\n",
        "\n",
        "print(\"C45 Model total score:\", totalScore/nFold)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating MLP Model with k-fold: \n",
            "TRAIN: --------\n",
            "VALIDATION: --------\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "MLP confusion matrix:\n",
            "[[15.  0.  0.]\n",
            " [ 0.  0.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "0\n",
            "tp=15.0\n",
            "p=15.0\n",
            "p_acc=15.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=0.0\n",
            "n=0.0\n",
            "n_acc=0.0\n",
            "error rate 0:\n",
            "0.0\n",
            "tp-rate/recall/sensitivity 0:\n",
            "1.0\n",
            "precision 0:\n",
            "1.0\n",
            "F-measure 0:\n",
            "1.0\n",
            "Balanced accuracy 0:\n",
            "0.5\n",
            "1\n",
            "tp=0.0\n",
            "p=0.0\n",
            "p_acc=0.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=15.0\n",
            "n=15.0\n",
            "n_acc=15.0\n",
            "error rate 1:\n",
            "0.0\n",
            "fp-rate 1:\n",
            "0.0\n",
            "specificity 1:\n",
            "1.0\n",
            "accuracy 1:\n",
            "1.0\n",
            "F-measure 1:\n",
            "1.0\n",
            "Balanced accuracy 1:\n",
            "1.0\n",
            "2\n",
            "tp=0.0\n",
            "p=0.0\n",
            "p_acc=0.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=15.0\n",
            "n=15.0\n",
            "n_acc=15.0\n",
            "error rate 2:\n",
            "0.0\n",
            "fp-rate 2:\n",
            "0.0\n",
            "specificity 2:\n",
            "1.0\n",
            "accuracy 2:\n",
            "1.0\n",
            "F-measure 2:\n",
            "1.0\n",
            "Balanced accuracy 2:\n",
            "1.0\n",
            "TRAIN: --------\n",
            "VALIDATION: --------\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "MLP confusion matrix:\n",
            "[[30.  0.  0.]\n",
            " [ 0.  0.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "0\n",
            "tp=30.0\n",
            "p=30.0\n",
            "p_acc=30.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=0.0\n",
            "n=0.0\n",
            "n_acc=0.0\n",
            "error rate 0:\n",
            "0.0\n",
            "tp-rate/recall/sensitivity 0:\n",
            "1.0\n",
            "precision 0:\n",
            "1.0\n",
            "F-measure 0:\n",
            "1.0\n",
            "Balanced accuracy 0:\n",
            "1.0\n",
            "1\n",
            "tp=0.0\n",
            "p=0.0\n",
            "p_acc=0.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=30.0\n",
            "n=30.0\n",
            "n_acc=30.0\n",
            "error rate 1:\n",
            "0.0\n",
            "fp-rate 1:\n",
            "0.0\n",
            "specificity 1:\n",
            "1.0\n",
            "accuracy 1:\n",
            "1.0\n",
            "F-measure 1:\n",
            "1.0\n",
            "Balanced accuracy 1:\n",
            "1.0\n",
            "2\n",
            "tp=0.0\n",
            "p=0.0\n",
            "p_acc=0.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=30.0\n",
            "n=30.0\n",
            "n_acc=30.0\n",
            "error rate 2:\n",
            "0.0\n",
            "fp-rate 2:\n",
            "0.0\n",
            "specificity 2:\n",
            "1.0\n",
            "accuracy 2:\n",
            "1.0\n",
            "F-measure 2:\n",
            "1.0\n",
            "Balanced accuracy 2:\n",
            "1.0\n",
            "TRAIN: --------\n",
            "VALIDATION: --------\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "MLP confusion matrix:\n",
            "[[45.  0.  0.]\n",
            " [ 0.  0.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "0\n",
            "tp=45.0\n",
            "p=45.0\n",
            "p_acc=45.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=0.0\n",
            "n=0.0\n",
            "n_acc=0.0\n",
            "error rate 0:\n",
            "0.0\n",
            "tp-rate/recall/sensitivity 0:\n",
            "1.0\n",
            "precision 0:\n",
            "1.0\n",
            "F-measure 0:\n",
            "1.0\n",
            "Balanced accuracy 0:\n",
            "1.0\n",
            "1\n",
            "tp=0.0\n",
            "p=0.0\n",
            "p_acc=0.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=45.0\n",
            "n=45.0\n",
            "n_acc=45.0\n",
            "error rate 1:\n",
            "0.0\n",
            "fp-rate 1:\n",
            "0.0\n",
            "specificity 1:\n",
            "1.0\n",
            "accuracy 1:\n",
            "1.0\n",
            "F-measure 1:\n",
            "1.0\n",
            "Balanced accuracy 1:\n",
            "1.0\n",
            "2\n",
            "tp=0.0\n",
            "p=0.0\n",
            "p_acc=0.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=45.0\n",
            "n=45.0\n",
            "n_acc=45.0\n",
            "error rate 2:\n",
            "0.0\n",
            "fp-rate 2:\n",
            "0.0\n",
            "specificity 2:\n",
            "1.0\n",
            "accuracy 2:\n",
            "1.0\n",
            "F-measure 2:\n",
            "1.0\n",
            "Balanced accuracy 2:\n",
            "1.0\n",
            "TRAIN: --------\n",
            "VALIDATION: --------\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 0]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "MLP confusion matrix:\n",
            "[[50.  0.  0.]\n",
            " [10.  0.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "0\n",
            "tp=50.0\n",
            "p=50.0\n",
            "p_acc=60.0\n",
            "fn=0.0\n",
            "fp=10.0\n",
            "tn=0.0\n",
            "n=10.0\n",
            "n_acc=0.0\n",
            "error rate 0:\n",
            "0.16666666666666666\n",
            "tp-rate/recall/sensitivity 0:\n",
            "1.0\n",
            "fp-rate 0:\n",
            "1.0\n",
            "specificity 0:\n",
            "0.0\n",
            "precision 0:\n",
            "0.8333333333333334\n",
            "accuracy 0:\n",
            "0.8333333333333334\n",
            "F-measure 0:\n",
            "0.9090909090909091\n",
            "Balanced accuracy 0:\n",
            "0.5\n",
            "1\n",
            "tp=0.0\n",
            "p=10.0\n",
            "p_acc=0.0\n",
            "fn=10.0\n",
            "fp=0.0\n",
            "tn=50.0\n",
            "n=50.0\n",
            "n_acc=60.0\n",
            "error rate 1:\n",
            "0.16666666666666666\n",
            "tp-rate/recall/sensitivity 1:\n",
            "0.0\n",
            "fp-rate 1:\n",
            "0.0\n",
            "specificity 1:\n",
            "1.0\n",
            "accuracy 1:\n",
            "0.8333333333333334\n",
            "F-measure 1:\n",
            "0.0\n",
            "Balanced accuracy 1:\n",
            "0.5\n",
            "2\n",
            "tp=0.0\n",
            "p=0.0\n",
            "p_acc=0.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=60.0\n",
            "n=60.0\n",
            "n_acc=60.0\n",
            "error rate 2:\n",
            "0.0\n",
            "fp-rate 2:\n",
            "0.0\n",
            "specificity 2:\n",
            "1.0\n",
            "accuracy 2:\n",
            "1.0\n",
            "F-measure 2:\n",
            "0.0\n",
            "Balanced accuracy 2:\n",
            "0.5\n",
            "TRAIN: --------\n",
            "VALIDATION: --------\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "MLP confusion matrix:\n",
            "[[50.  0.  0.]\n",
            " [25.  0.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "0\n",
            "tp=50.0\n",
            "p=50.0\n",
            "p_acc=75.0\n",
            "fn=0.0\n",
            "fp=25.0\n",
            "tn=0.0\n",
            "n=25.0\n",
            "n_acc=0.0\n",
            "error rate 0:\n",
            "0.3333333333333333\n",
            "tp-rate/recall/sensitivity 0:\n",
            "1.0\n",
            "fp-rate 0:\n",
            "1.0\n",
            "specificity 0:\n",
            "0.0\n",
            "precision 0:\n",
            "0.6666666666666666\n",
            "accuracy 0:\n",
            "0.6666666666666666\n",
            "F-measure 0:\n",
            "0.8\n",
            "Balanced accuracy 0:\n",
            "0.5\n",
            "1\n",
            "tp=0.0\n",
            "p=25.0\n",
            "p_acc=0.0\n",
            "fn=25.0\n",
            "fp=0.0\n",
            "tn=50.0\n",
            "n=50.0\n",
            "n_acc=75.0\n",
            "error rate 1:\n",
            "0.3333333333333333\n",
            "tp-rate/recall/sensitivity 1:\n",
            "0.0\n",
            "fp-rate 1:\n",
            "0.0\n",
            "specificity 1:\n",
            "1.0\n",
            "accuracy 1:\n",
            "0.6666666666666666\n",
            "F-measure 1:\n",
            "0.0\n",
            "Balanced accuracy 1:\n",
            "0.5\n",
            "2\n",
            "tp=0.0\n",
            "p=0.0\n",
            "p_acc=0.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=75.0\n",
            "n=75.0\n",
            "n_acc=75.0\n",
            "error rate 2:\n",
            "0.0\n",
            "fp-rate 2:\n",
            "0.0\n",
            "specificity 2:\n",
            "1.0\n",
            "accuracy 2:\n",
            "1.0\n",
            "F-measure 2:\n",
            "0.0\n",
            "Balanced accuracy 2:\n",
            "0.5\n",
            "TRAIN: --------\n",
            "VALIDATION: --------\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "MLP confusion matrix:\n",
            "[[50.  0.  0.]\n",
            " [40.  0.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "0\n",
            "tp=50.0\n",
            "p=50.0\n",
            "p_acc=90.0\n",
            "fn=0.0\n",
            "fp=40.0\n",
            "tn=0.0\n",
            "n=40.0\n",
            "n_acc=0.0\n",
            "error rate 0:\n",
            "0.4444444444444444\n",
            "tp-rate/recall/sensitivity 0:\n",
            "1.0\n",
            "fp-rate 0:\n",
            "1.0\n",
            "specificity 0:\n",
            "0.0\n",
            "precision 0:\n",
            "0.5555555555555556\n",
            "accuracy 0:\n",
            "0.5555555555555556\n",
            "F-measure 0:\n",
            "0.7142857142857143\n",
            "Balanced accuracy 0:\n",
            "0.5\n",
            "1\n",
            "tp=0.0\n",
            "p=40.0\n",
            "p_acc=0.0\n",
            "fn=40.0\n",
            "fp=0.0\n",
            "tn=50.0\n",
            "n=50.0\n",
            "n_acc=90.0\n",
            "error rate 1:\n",
            "0.4444444444444444\n",
            "tp-rate/recall/sensitivity 1:\n",
            "0.0\n",
            "fp-rate 1:\n",
            "0.0\n",
            "specificity 1:\n",
            "1.0\n",
            "accuracy 1:\n",
            "0.5555555555555556\n",
            "F-measure 1:\n",
            "0.0\n",
            "Balanced accuracy 1:\n",
            "0.5\n",
            "2\n",
            "tp=0.0\n",
            "p=0.0\n",
            "p_acc=0.0\n",
            "fn=0.0\n",
            "fp=0.0\n",
            "tn=90.0\n",
            "n=90.0\n",
            "n_acc=90.0\n",
            "error rate 2:\n",
            "0.0\n",
            "fp-rate 2:\n",
            "0.0\n",
            "specificity 2:\n",
            "1.0\n",
            "accuracy 2:\n",
            "1.0\n",
            "F-measure 2:\n",
            "0.0\n",
            "Balanced accuracy 2:\n",
            "0.5\n",
            "TRAIN: --------\n",
            "VALIDATION: --------\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [0, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "MLP confusion matrix:\n",
            "[[50.  0.  0.]\n",
            " [50.  0.  0.]\n",
            " [ 5.  0.  0.]]\n",
            "0\n",
            "tp=50.0\n",
            "p=50.0\n",
            "p_acc=105.0\n",
            "fn=0.0\n",
            "fp=55.0\n",
            "tn=0.0\n",
            "n=55.0\n",
            "n_acc=0.0\n",
            "error rate 0:\n",
            "0.5238095238095238\n",
            "tp-rate/recall/sensitivity 0:\n",
            "1.0\n",
            "fp-rate 0:\n",
            "1.0\n",
            "specificity 0:\n",
            "0.0\n",
            "precision 0:\n",
            "0.47619047619047616\n",
            "accuracy 0:\n",
            "0.47619047619047616\n",
            "F-measure 0:\n",
            "0.6451612903225806\n",
            "Balanced accuracy 0:\n",
            "0.5\n",
            "1\n",
            "tp=0.0\n",
            "p=50.0\n",
            "p_acc=0.0\n",
            "fn=50.0\n",
            "fp=0.0\n",
            "tn=55.0\n",
            "n=55.0\n",
            "n_acc=105.0\n",
            "error rate 1:\n",
            "0.47619047619047616\n",
            "tp-rate/recall/sensitivity 1:\n",
            "0.0\n",
            "fp-rate 1:\n",
            "0.0\n",
            "specificity 1:\n",
            "1.0\n",
            "accuracy 1:\n",
            "0.5238095238095238\n",
            "F-measure 1:\n",
            "0.0\n",
            "Balanced accuracy 1:\n",
            "0.5\n",
            "2\n",
            "tp=0.0\n",
            "p=5.0\n",
            "p_acc=0.0\n",
            "fn=5.0\n",
            "fp=0.0\n",
            "tn=100.0\n",
            "n=100.0\n",
            "n_acc=105.0\n",
            "error rate 2:\n",
            "0.047619047619047616\n",
            "tp-rate/recall/sensitivity 2:\n",
            "0.0\n",
            "fp-rate 2:\n",
            "0.0\n",
            "specificity 2:\n",
            "1.0\n",
            "accuracy 2:\n",
            "0.9523809523809523\n",
            "F-measure 2:\n",
            "0.0\n",
            "Balanced accuracy 2:\n",
            "0.5\n",
            "TRAIN: --------\n",
            "VALIDATION: --------\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "MLP confusion matrix:\n",
            "[[50.  0.  0.]\n",
            " [50.  0.  0.]\n",
            " [20.  0.  0.]]\n",
            "0\n",
            "tp=50.0\n",
            "p=50.0\n",
            "p_acc=120.0\n",
            "fn=0.0\n",
            "fp=70.0\n",
            "tn=0.0\n",
            "n=70.0\n",
            "n_acc=0.0\n",
            "error rate 0:\n",
            "0.5833333333333334\n",
            "tp-rate/recall/sensitivity 0:\n",
            "1.0\n",
            "fp-rate 0:\n",
            "1.0\n",
            "specificity 0:\n",
            "0.0\n",
            "precision 0:\n",
            "0.4166666666666667\n",
            "accuracy 0:\n",
            "0.4166666666666667\n",
            "F-measure 0:\n",
            "0.5882352941176471\n",
            "Balanced accuracy 0:\n",
            "0.5\n",
            "1\n",
            "tp=0.0\n",
            "p=50.0\n",
            "p_acc=0.0\n",
            "fn=50.0\n",
            "fp=0.0\n",
            "tn=70.0\n",
            "n=70.0\n",
            "n_acc=120.0\n",
            "error rate 1:\n",
            "0.4166666666666667\n",
            "tp-rate/recall/sensitivity 1:\n",
            "0.0\n",
            "fp-rate 1:\n",
            "0.0\n",
            "specificity 1:\n",
            "1.0\n",
            "accuracy 1:\n",
            "0.5833333333333334\n",
            "F-measure 1:\n",
            "0.0\n",
            "Balanced accuracy 1:\n",
            "0.5\n",
            "2\n",
            "tp=0.0\n",
            "p=20.0\n",
            "p_acc=0.0\n",
            "fn=20.0\n",
            "fp=0.0\n",
            "tn=100.0\n",
            "n=100.0\n",
            "n_acc=120.0\n",
            "error rate 2:\n",
            "0.16666666666666666\n",
            "tp-rate/recall/sensitivity 2:\n",
            "0.0\n",
            "fp-rate 2:\n",
            "0.0\n",
            "specificity 2:\n",
            "1.0\n",
            "accuracy 2:\n",
            "0.8333333333333334\n",
            "F-measure 2:\n",
            "0.0\n",
            "Balanced accuracy 2:\n",
            "0.5\n",
            "TRAIN: --------\n",
            "VALIDATION: --------\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "MLP confusion matrix:\n",
            "[[50.  0.  0.]\n",
            " [50.  0.  0.]\n",
            " [35.  0.  0.]]\n",
            "0\n",
            "tp=50.0\n",
            "p=50.0\n",
            "p_acc=135.0\n",
            "fn=0.0\n",
            "fp=85.0\n",
            "tn=0.0\n",
            "n=85.0\n",
            "n_acc=0.0\n",
            "error rate 0:\n",
            "0.6296296296296297\n",
            "tp-rate/recall/sensitivity 0:\n",
            "1.0\n",
            "fp-rate 0:\n",
            "1.0\n",
            "specificity 0:\n",
            "0.0\n",
            "precision 0:\n",
            "0.37037037037037035\n",
            "accuracy 0:\n",
            "0.37037037037037035\n",
            "F-measure 0:\n",
            "0.5405405405405406\n",
            "Balanced accuracy 0:\n",
            "0.5\n",
            "1\n",
            "tp=0.0\n",
            "p=50.0\n",
            "p_acc=0.0\n",
            "fn=50.0\n",
            "fp=0.0\n",
            "tn=85.0\n",
            "n=85.0\n",
            "n_acc=135.0\n",
            "error rate 1:\n",
            "0.37037037037037035\n",
            "tp-rate/recall/sensitivity 1:\n",
            "0.0\n",
            "fp-rate 1:\n",
            "0.0\n",
            "specificity 1:\n",
            "1.0\n",
            "accuracy 1:\n",
            "0.6296296296296297\n",
            "F-measure 1:\n",
            "0.0\n",
            "Balanced accuracy 1:\n",
            "0.5\n",
            "2\n",
            "tp=0.0\n",
            "p=35.0\n",
            "p_acc=0.0\n",
            "fn=35.0\n",
            "fp=0.0\n",
            "tn=100.0\n",
            "n=100.0\n",
            "n_acc=135.0\n",
            "error rate 2:\n",
            "0.25925925925925924\n",
            "tp-rate/recall/sensitivity 2:\n",
            "0.0\n",
            "fp-rate 2:\n",
            "0.0\n",
            "specificity 2:\n",
            "1.0\n",
            "accuracy 2:\n",
            "0.7407407407407407\n",
            "F-measure 2:\n",
            "0.0\n",
            "Balanced accuracy 2:\n",
            "0.5\n",
            "TRAIN: --------\n",
            "VALIDATION: --------\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "[0, 0]  vs  [1, 1]\n",
            "MLP confusion matrix:\n",
            "[[50.  0.  0.]\n",
            " [50.  0.  0.]\n",
            " [50.  0.  0.]]\n",
            "0\n",
            "tp=50.0\n",
            "p=50.0\n",
            "p_acc=150.0\n",
            "fn=0.0\n",
            "fp=100.0\n",
            "tn=0.0\n",
            "n=100.0\n",
            "n_acc=0.0\n",
            "error rate 0:\n",
            "0.6666666666666666\n",
            "tp-rate/recall/sensitivity 0:\n",
            "1.0\n",
            "fp-rate 0:\n",
            "1.0\n",
            "specificity 0:\n",
            "0.0\n",
            "precision 0:\n",
            "0.3333333333333333\n",
            "accuracy 0:\n",
            "0.3333333333333333\n",
            "F-measure 0:\n",
            "0.5\n",
            "Balanced accuracy 0:\n",
            "0.5\n",
            "1\n",
            "tp=0.0\n",
            "p=50.0\n",
            "p_acc=0.0\n",
            "fn=50.0\n",
            "fp=0.0\n",
            "tn=100.0\n",
            "n=100.0\n",
            "n_acc=150.0\n",
            "error rate 1:\n",
            "0.3333333333333333\n",
            "tp-rate/recall/sensitivity 1:\n",
            "0.0\n",
            "fp-rate 1:\n",
            "0.0\n",
            "specificity 1:\n",
            "1.0\n",
            "accuracy 1:\n",
            "0.6666666666666666\n",
            "F-measure 1:\n",
            "0.0\n",
            "Balanced accuracy 1:\n",
            "0.5\n",
            "2\n",
            "tp=0.0\n",
            "p=50.0\n",
            "p_acc=0.0\n",
            "fn=50.0\n",
            "fp=0.0\n",
            "tn=100.0\n",
            "n=100.0\n",
            "n_acc=150.0\n",
            "error rate 2:\n",
            "0.3333333333333333\n",
            "tp-rate/recall/sensitivity 2:\n",
            "0.0\n",
            "fp-rate 2:\n",
            "0.0\n",
            "specificity 2:\n",
            "1.0\n",
            "accuracy 2:\n",
            "0.6666666666666666\n",
            "F-measure 2:\n",
            "0.0\n",
            "Balanced accuracy 2:\n",
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K2nh916YD9C",
        "colab_type": "text"
      },
      "source": [
        "## III. Menyimpan (save) model pembelajaran"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2AjTkSbYD9D",
        "colab_type": "code",
        "outputId": "e3b04657-7398-4909-8393-dcefd0c87bc5",
        "colab": {}
      },
      "source": [
        "# Read data\n",
        "data = pd.read_csv(\"iris.csv\", header=None, names=['attr1', 'attr2', 'attr3', 'attr4', 'target'])\n",
        "data = MyC45.handleContinuousAttribute(data)\n",
        "\n",
        "# Learning\n",
        "# t = MyC45.MyTree(_targetAttribute = 'target')\n",
        "# t.buildTreeInit(trainingSet = data)\n",
        "\n",
        "# Save model\n",
        "em.saveModel(tree, \"split_tree.pickle\")\n",
        "em.saveModel(mlp, \"split_mlp.pickle\")\n",
        "em.saveModel(t, \"myc45_model.pickle\")\n",
        "em.saveModel(mlp2, \"mlp_kfold.pickle\")\n",
        "em.saveModel(t2,\"myc45_model_kfold.pickle\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entropy not 0 but already ran out attributes\n",
            "Entropy not 0 but already ran out attributes\n",
            "Entropy not 0 but already ran out attributes\n",
            "Entropy not 0 but already ran out attributes\n",
            "Model saved\n",
            "Model saved\n",
            "Model saved\n",
            "Model saved\n",
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxsIbcIGYD9H",
        "colab_type": "text"
      },
      "source": [
        "## IV. Membaca (load) model pembelajaran"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JiYJbvQYD9I",
        "colab_type": "raw"
      },
      "source": [
        "# Load model\n",
        "t_new = em.loadModel(\"myc45_model.pickle\")\n",
        "split_tree_new = em.loadModel(\"split_tree.pickle\")\n",
        "split_mlp_new = em.loadModel(\"split_mlp.pickle\")\n",
        "mlp2_kfold_new = em.loadModel(\"mlp_kfold.pickle\")\n",
        "t2_kfold_new = em.loadModel(\"myc45_model_kfold.pickle\")\n",
        "\n",
        "confusion_matrixMLP = np.zeros((3, 3))\n",
        "for i in range(len(test_dataMLP)):\n",
        "    test = list(test_dataMLP.iloc[i,:-mlp.outputs])\n",
        "    target = list(test_dataMLP.iloc[i,mlp.inputs:])\n",
        "    estimate = split_mlp_new.estimate(test)\n",
        "    # print(estimate)\n",
        "    for i in range(len(estimate)):\n",
        "        estimate[i] = round(estimate[i])\n",
        "    # print(estimate)\n",
        "    # print(target)\n",
        "    row = -1\n",
        "    if (target == [0, 0]):\n",
        "        row = 0\n",
        "    elif (target == [0, 1]):\n",
        "        row = 1\n",
        "    elif (target == [1, 1]):\n",
        "        row = 2\n",
        "    column = -1\n",
        "    if (estimate == [0, 0]):\n",
        "        column = 0\n",
        "    elif (estimate == [0, 1]):\n",
        "        column = 1\n",
        "    elif (estimate == [1, 1]):\n",
        "        column = 2\n",
        "    if (column >= 0 and row >= 0):\n",
        "        confusion_matrixMLP[row][column] += 1\n",
        "print(\"MLP confusion matrix:\")\n",
        "print(confusion_matrixMLP)\n",
        "\n",
        "confusion_matrixDTL = np.zeros((3, 3))\n",
        "# tree.printTree()\n",
        "for i in range(len(test_dataDTL)):\n",
        "    test = test_dataDTL.iloc[i]\n",
        "    target = test[\"target\"]\n",
        "    test = test.to_dict()\n",
        "    for key in test:\n",
        "        test[key] = str(test[key])\n",
        "    # print(test)\n",
        "    estimate = split_tree_new.predict(test)\n",
        "    # print(estimate)\n",
        "    row = -1\n",
        "    row = int(target)\n",
        "    column = -1\n",
        "    column = int(estimate)\n",
        "    if (column >= 0 and row >= 0):\n",
        "        confusion_matrixDTL[row][column] += 1\n",
        "print(\"DTL confusion matrix:\")\n",
        "print(confusion_matrixDTL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9AY7bU6YD9I",
        "colab_type": "text"
      },
      "source": [
        "## V. Klasifikasi menggunakan model pada poin IV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLCu2qyYD9J",
        "colab_type": "raw"
      },
      "source": [
        "# print(t_new.predict({}))\n",
        "# ANN\n",
        "values = [1.2, 3.2, 9.9, 4.3]\n",
        "prediction = mlp2_kfold_new.estimate(values)\n",
        "# DTL\n",
        "t2_kfold_new = MyC45.MyTree(_targetAttribute = 'target')\n",
        "t2_kfold_new.buildTreeInit(trainingSet = data)\n",
        "values = {\n",
        "   'attr1' : 1.2,\n",
        "   'attr2' : 2.3,\n",
        "   'attr3' : 9.9,\n",
        "   'attr4' : 3.4\n",
        "}\n",
        "prediction = t.predict(values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UIiBIN0YD9K",
        "colab_type": "text"
      },
      "source": [
        "## VI. Analisis hasil eksperimen poin I dan II\n",
        "    \n",
        "### Split train 90% dan test 10%\n",
        "    Pada eksperimen point I Skema split train 90% dan test 10% bagian MLP, menghasilkan confusion matrix<br>\n",
        "\n",
        "[5 0 0<br>\n",
        "0 6 0<br>\n",
        "0 3 1]<br>\n",
        "   \n",
        "    dimana pada row 0 dan row 1, model kami berhasil memprediksi seluruh kasus dengan benar sedangkan pada row 2, model kami hanya memprediksi 1 dari 4 saja yang benar. hal ini menunjukkan bahwa ada kasus dimana model kami mengembalikan false positive.\n",
        "    \n",
        "    Lalu pada training DTL dengan Skema I model kami menghasilkan confusion matrix sebagai berikut <br>\n",
        "[6 0 0<br>\n",
        "1 3 1<br>\n",
        "0 0 4]<br>\n",
        "\n",
        "    Pada row 0 model kami berhasil memprediksi true positive seluruhnya. lalu pada row 1, model kami berhasil memprediksi benar 3 dari 5 namun untuk sisa 2nya salah. Selain itu pada row 2, model kami berhasil memprediksi true positive seluruh kasus. Salah satu faktor penyebab kesalahan dalam memprediksi data adalah faktor shuffle dalam training, kurangnya iterasi, overfit data, kurang spesifiknya data yang tersedia, atau bisa juga kurang banyaknya data. Untuk MLP, beberapa faktor lainnya adalah karena kurangnya layer pada hidden node sehingga mengurangi akurasi dan juga faktor batch size yang tidak seimbang.\n",
        "\n",
        "### K-Fold Cross Validation\n",
        "    K-Fold Cross-Validation adalah resampling procedure yang digunakan untuk evaluasi model ML ketika dataset yang tersedia sangat sedikit. Prosedur ini memiliki parameter tunggal k yang menandakan seberapa banyak grup sample data yang diberikan akan terbagi. \n",
        "\n",
        "    Untuk kasus ini, k = 10 (ten fold cross validation). 10 dipilih karena menurut penelitian telah dibuktikan k yang bernilai 10 memiliki probabilitas untuk menghasilkan evaluasi model ML yang memiliki bias rendah dan variansi yang minimal.\n",
        "\n",
        "#### Prosedur yang dilakukan untuk k-Fold:\n",
        "1.  Sebisa mungkin split dataset original menjadi group sebanyak k\n",
        "2. Untuk setiap group k:\n",
        "     a. Ambil satu partisi sebagai validation dataset\n",
        "     b. dataset yang tersisa dijadikan training dataset\n",
        "     c. gunakan dataset training untuk membangun dan melatih model ML\n",
        "     d. menghitung skor evaluasi dengan validation dataset dan buang model tersebut\n",
        "3. Tarik kesimpulan /rata-rata skor dari model ML menurut setiap skor dari tahap evaluasi\n",
        "\n",
        "#### Constraint:\n",
        "1. Setiap group harus unique, setiap observasi (row) pada dataset hanya boleh menjadi bagian dari validation set hanya 1x saja\n",
        "2. Suatu observasi dapat menjadi bagian dari training set atau validation set pada suatu iterasi, namun tidak kedua-duanya sekaligus dalam satu iterasi\n",
        "\n",
        "|Iteration|Training set obsevations|Testing set observations|\n",
        "|---------|------------------------|------------------------|\n",
        "|1|[ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]|[0 1 2 3 4]|\n",
        "|2|[ 0  1  2  3  4 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]|[5 6 7 8 9]|\n",
        "|3|[ 0  1  2  3  4  5  6  7  8  9 15 16 17 18 19 20 21 22 23 24]|[10 11 12 13 14]|\n",
        "|4|[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 20 21 22 23 24]|[15 16 17 18 19]|\n",
        "|5|[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]|[20 21 22 23 24]|\n",
        "    \n",
        "    \n",
        "### Kesimpulan\n",
        "    Jika dibandingkan dengan 10 fold Cross Validation, tentunya ada kelemahan dan kelebihan dari skema ke-2 ini. Dimana untuk Skema 10 Fold Cross Validation, training dilakukan 10 kali dengan men-switch training data dan test data yang ada. Dari sini, dapat kita temukan pasangan training data dan test data yang memiliki accuracy paling besar dari 10 kali iterasi pelatihan model. \n",
        "\n",
        "    Kelemahan dari 10 fold Cross Validation tentunya terletak pada waktu yang diberikan untuk melatih modelnya. Dimana jika kita menggunakan 10 Fold Cross Validation, tentunya pelatihan model akan lebih lama namun akan mendapatkan model yang lebih akurat. Kenapa 10? karena nilai 10 adalah nilai yang telah ditemukan melalui eksperimen untuk secara umum menghasilkan estimasi keterampilan model dengan bias rendah dan varian yang tidak terlalu bervariasi."
      ]
    }
  ]
}