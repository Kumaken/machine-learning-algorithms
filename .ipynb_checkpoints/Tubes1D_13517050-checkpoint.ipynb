{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF3270 Pembelajaran Mesin - Tugas Besar 1D\n",
    "## Anggota kelompok :\n",
    "1. T. Antra Oksidian Tafly / 13517020\n",
    "2. Christopher Billy S. / 13517050\n",
    "3. Abel Stanley / 13517068\n",
    "4. Ferdy Santoso / 13517116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import MyC45\n",
    "import ExternalModel as em"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Skema split train 90% dan test 10%, dan menampilkan kinerja serta confusion matrixnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP confusion matrix:\n",
      "[[6. 0. 0.]\n",
      " [0. 3. 0.]\n",
      " [0. 5. 1.]]\n",
      "0\n",
      "tp=6.0\n",
      "p=6.0\n",
      "p_acc=6.0\n",
      "fn=0.0\n",
      "fp=0.0\n",
      "tn=9.0\n",
      "n=9.0\n",
      "n_acc=9.0\n",
      "error rate 0:\n",
      "0.0\n",
      "tp-rate/recall/sensitivity 0:\n",
      "1.0\n",
      "fp-rate 0:\n",
      "0.0\n",
      "specificity 0:\n",
      "1.0\n",
      "precision 0:\n",
      "1.0\n",
      "accuracy 0:\n",
      "1.0\n",
      "F-measure 0:\n",
      "1.0\n",
      "Balanced accuracy 0:\n",
      "1.0\n",
      "1\n",
      "tp=3.0\n",
      "p=3.0\n",
      "p_acc=8.0\n",
      "fn=0.0\n",
      "fp=5.0\n",
      "tn=7.0\n",
      "n=12.0\n",
      "n_acc=7.0\n",
      "error rate 1:\n",
      "0.3333333333333333\n",
      "tp-rate/recall/sensitivity 1:\n",
      "1.0\n",
      "fp-rate 1:\n",
      "0.4166666666666667\n",
      "specificity 1:\n",
      "0.5833333333333334\n",
      "precision 1:\n",
      "0.375\n",
      "accuracy 1:\n",
      "0.6666666666666666\n",
      "F-measure 1:\n",
      "0.5454545454545454\n",
      "Balanced accuracy 1:\n",
      "0.7916666666666667\n",
      "2\n",
      "tp=1.0\n",
      "p=6.0\n",
      "p_acc=1.0\n",
      "fn=5.0\n",
      "fp=0.0\n",
      "tn=9.0\n",
      "n=9.0\n",
      "n_acc=14.0\n",
      "error rate 2:\n",
      "0.3333333333333333\n",
      "tp-rate/recall/sensitivity 2:\n",
      "0.16666666666666666\n",
      "fp-rate 2:\n",
      "0.0\n",
      "specificity 2:\n",
      "1.0\n",
      "precision 2:\n",
      "1.0\n",
      "accuracy 2:\n",
      "0.6666666666666666\n",
      "F-measure 2:\n",
      "0.2857142857142857\n",
      "Balanced accuracy 2:\n",
      "0.5833333333333334\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "DTL confusion matrix:\n",
      "[[7. 0. 0.]\n",
      " [0. 3. 1.]\n",
      " [0. 0. 4.]]\n",
      "0\n",
      "tp=7.0\n",
      "p=7.0\n",
      "p_acc=7.0\n",
      "fn=0.0\n",
      "fp=0.0\n",
      "tn=8.0\n",
      "n=8.0\n",
      "n_acc=8.0\n",
      "error rate 0:\n",
      "0.0\n",
      "tp-rate/recall/sensitivity 0:\n",
      "1.0\n",
      "fp-rate 0:\n",
      "0.0\n",
      "specificity 0:\n",
      "1.0\n",
      "precision 0:\n",
      "1.0\n",
      "accuracy 0:\n",
      "1.0\n",
      "F-measure 0:\n",
      "1.0\n",
      "Balanced accuracy 0:\n",
      "1.0\n",
      "1\n",
      "tp=3.0\n",
      "p=4.0\n",
      "p_acc=3.0\n",
      "fn=1.0\n",
      "fp=0.0\n",
      "tn=11.0\n",
      "n=11.0\n",
      "n_acc=12.0\n",
      "error rate 1:\n",
      "0.06666666666666667\n",
      "tp-rate/recall/sensitivity 1:\n",
      "0.75\n",
      "fp-rate 1:\n",
      "0.0\n",
      "specificity 1:\n",
      "1.0\n",
      "precision 1:\n",
      "1.0\n",
      "accuracy 1:\n",
      "0.9333333333333333\n",
      "F-measure 1:\n",
      "0.8571428571428571\n",
      "Balanced accuracy 1:\n",
      "0.875\n",
      "2\n",
      "tp=4.0\n",
      "p=4.0\n",
      "p_acc=5.0\n",
      "fn=0.0\n",
      "fp=1.0\n",
      "tn=10.0\n",
      "n=11.0\n",
      "n_acc=10.0\n",
      "error rate 2:\n",
      "0.06666666666666667\n",
      "tp-rate/recall/sensitivity 2:\n",
      "1.0\n",
      "fp-rate 2:\n",
      "0.09090909090909091\n",
      "specificity 2:\n",
      "0.9090909090909091\n",
      "precision 2:\n",
      "0.8\n",
      "accuracy 2:\n",
      "0.9333333333333333\n",
      "F-measure 2:\n",
      "0.888888888888889\n",
      "Balanced accuracy 2:\n",
      "0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "from MultiLayerPerceptron import MultiLayerPerceptron\n",
    "from MyC45 import MyTree\n",
    "from MyC45 import handleContinuousAttribute\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "def MLP(data, batch_size):\n",
    "\n",
    "    #data = load_iris()\n",
    "    # list1 = list(data.iloc[0,:-2])\n",
    "    # print(list1)\n",
    "    # target = list(data.iloc[0,4:])\n",
    "    # print(target)\n",
    "    mlp = MultiLayerPerceptron(_layers=1 , _bias=1, _inputs=4, _outputs=2, _learningRate=0.01, _maxIter=50)\n",
    "\n",
    "    for i in range(mlp.maxIter):\n",
    "        mlp.totalError = 0\n",
    "        data = shuffle(data)\n",
    "        #print(data.data[0])\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            row = list(data.iloc[j,:-mlp.outputs])\n",
    "            target = list(data.iloc[j,mlp.inputs:])\n",
    "            mlp.estimate(row)\n",
    "            #mlp.estimate(data.data[j])\n",
    "            mlp.updateDeltaWeight(target)\n",
    "            if j % batch_size == 0:\n",
    "                mlp.updateWeight()\n",
    "                mlp.updateTotalError(target)\n",
    "                # print(\"at iteration \", i, \" error = \" + str(mlp.totalError))\n",
    "        if j % batch_size != 0:\n",
    "            mlp.updateWeight()\n",
    "            mlp.updateTotalError(target)\n",
    "            # print(\"at iteration \", i, \" error = \" + str(mlp.totalError))\n",
    "\n",
    "\n",
    "        if(mlp.totalError < 0.01):\n",
    "            break\n",
    "\n",
    "    return mlp\n",
    "\n",
    "dataMLP = pd.read_csv(\"irisMLP.csv\")\n",
    "training_data = dataMLP.sample(frac = 0.9)\n",
    "test_dataMLP = dataMLP.drop(training_data.index)\n",
    "mlp = MLP(training_data, 10)\n",
    "confusion_matrixMLP = np.zeros((3, 3))\n",
    "for i in range(len(test_dataMLP)):\n",
    "    test = list(test_dataMLP.iloc[i,:-mlp.outputs])\n",
    "    target = list(test_dataMLP.iloc[i,mlp.inputs:])\n",
    "    estimate = mlp.estimate(test)\n",
    "    # print(estimate)\n",
    "    for i in range(len(estimate)):\n",
    "        estimate[i] = round(estimate[i])\n",
    "    # print(estimate)\n",
    "    # print(target)\n",
    "    row = -1\n",
    "    if (target == [0, 0]):\n",
    "        row = 0\n",
    "    elif (target == [0, 1]):\n",
    "        row = 1\n",
    "    elif (target == [1, 1]):\n",
    "        row = 2\n",
    "    column = -1\n",
    "    if (estimate == [0, 0]):\n",
    "        column = 0\n",
    "    elif (estimate == [0, 1]):\n",
    "        column = 1\n",
    "    elif (estimate == [1, 1]):\n",
    "        column = 2\n",
    "    if (column >= 0 and row >= 0):\n",
    "        confusion_matrixMLP[row][column] += 1\n",
    "print(\"MLP confusion matrix:\")\n",
    "print(confusion_matrixMLP)\n",
    "\n",
    "# Penghitungan kinerja\n",
    "total = 0\n",
    "for i in range(len(confusion_matrixMLP)):\n",
    "    for j in range(len(confusion_matrixMLP[i])):\n",
    "        total+=confusion_matrixMLP[i][j]\n",
    "if (total!=0):\n",
    "    for i in range(len(confusion_matrixMLP)):\n",
    "        print(i)\n",
    "        p = 0\n",
    "        p_acc = 0\n",
    "        error_rate = 0\n",
    "        tp = confusion_matrixMLP[i][i]\n",
    "        print(\"tp=\" + str(tp))\n",
    "        fn = 0\n",
    "        fp = 0\n",
    "        for j in range(len(confusion_matrixMLP[i])):\n",
    "            p += confusion_matrixMLP[i][j]\n",
    "            p_acc += confusion_matrixMLP[j][i]\n",
    "            if (j!=i):\n",
    "                fn += confusion_matrixMLP[i][j]\n",
    "                fp += confusion_matrixMLP[j][i]\n",
    "        tn = total - (tp + fn + fp)\n",
    "        n = total-p\n",
    "        n_acc = total-p_acc\n",
    "        print(\"p=\" + str(p))\n",
    "        print(\"p_acc=\" + str(p_acc))\n",
    "        print(\"fn=\" + str(fn))\n",
    "        print(\"fp=\" + str(fp))\n",
    "        print(\"tn=\" + str(tn))\n",
    "        print(\"n=\" + str(n))\n",
    "        print(\"n_acc=\" + str(n_acc))\n",
    "\n",
    "        print('error rate ' + str(i) + \":\")\n",
    "        error_rate = float(fn+fp) / total\n",
    "        print(error_rate)\n",
    "\n",
    "        if (p!=0):\n",
    "            recall = float(tp)/p\n",
    "            print('tp-rate/recall/sensitivity ' + str(i) + \":\")\n",
    "            print(recall)\n",
    "\n",
    "        if (n!=0):\n",
    "            fp_rate = float(fp)/n\n",
    "            print('fp-rate ' + str(i) + \":\")\n",
    "            print(fp_rate)\n",
    "\n",
    "        if (n!=0):\n",
    "            specificity = float(tn)/n\n",
    "            print('specificity ' + str(i) + \":\")\n",
    "            print(specificity)\n",
    "\n",
    "        if (p_acc!=0):\n",
    "            precision = float(tp)/p_acc\n",
    "            print('precision ' + str(i) + \":\")\n",
    "            print(precision)\n",
    "\n",
    "        if (n!=0):\n",
    "            accuracy = float(tp + tn)/total\n",
    "            print('accuracy ' + str(i) + \":\")\n",
    "            print(accuracy)\n",
    "\n",
    "        if (precision+recall != 0):\n",
    "            f_measure = 2 * float(precision * recall) / (precision + recall)\n",
    "            print('F-measure ' + str(i) + \":\")\n",
    "            print(f_measure)\n",
    "\n",
    "        balanced_accuracy = float(recall + specificity) / 2\n",
    "        print('Balanced accuracy ' + str(i) + \":\")\n",
    "        print(balanced_accuracy)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "dataDTL = pd.read_csv(\"irisDTL.csv\")\n",
    "dataDTL = handleContinuousAttribute(dataDTL)\n",
    "training_dataDTL = dataDTL.sample(frac = 0.9)\n",
    "test_dataDTL = dataDTL.drop(training_dataDTL.index)\n",
    "tree = MyTree(_targetAttribute = \"target\")\n",
    "tree.buildTreeInit(trainingSet=training_dataDTL)\n",
    "confusion_matrixDTL = np.zeros((3, 3))\n",
    "# tree.printTree()\n",
    "for i in range(len(test_dataDTL)):\n",
    "    test = test_dataDTL.iloc[i]\n",
    "    target = test[\"target\"]\n",
    "    test = test.to_dict()\n",
    "    for key in test:\n",
    "        test[key] = str(test[key])\n",
    "    # print(test)\n",
    "    estimate = tree.predict(test)\n",
    "    # print(estimate)\n",
    "    row = -1\n",
    "    row = int(target)\n",
    "    column = -1\n",
    "    column = int(estimate)\n",
    "    if (column >= 0 and row >= 0):\n",
    "        confusion_matrixDTL[row][column] += 1\n",
    "print(\"DTL confusion matrix:\")\n",
    "print(confusion_matrixDTL)\n",
    "\n",
    "# Penghitungan kinerja\n",
    "total = 0\n",
    "for i in range(len(confusion_matrixDTL)):\n",
    "    for j in range(len(confusion_matrixDTL[i])):\n",
    "        total+=confusion_matrixDTL[i][j]\n",
    "if (total!=0):\n",
    "    for i in range(len(confusion_matrixDTL)):\n",
    "        print(i)\n",
    "        p = 0\n",
    "        p_acc = 0\n",
    "        error_rate = 0\n",
    "        tp = confusion_matrixDTL[i][i]\n",
    "        print(\"tp=\" + str(tp))\n",
    "        fn = 0\n",
    "        fp = 0\n",
    "        for j in range(len(confusion_matrixDTL[i])):\n",
    "            p += confusion_matrixDTL[i][j]\n",
    "            p_acc += confusion_matrixDTL[j][i]\n",
    "            if (j!=i):\n",
    "                fn += confusion_matrixDTL[i][j]\n",
    "                fp += confusion_matrixDTL[j][i]\n",
    "        tn = total - (tp + fn + fp)\n",
    "        n = total-p\n",
    "        n_acc = total-p_acc\n",
    "        print(\"p=\" + str(p))\n",
    "        print(\"p_acc=\" + str(p_acc))\n",
    "        print(\"fn=\" + str(fn))\n",
    "        print(\"fp=\" + str(fp))\n",
    "        print(\"tn=\" + str(tn))\n",
    "        print(\"n=\" + str(n))\n",
    "        print(\"n_acc=\" + str(n_acc))\n",
    "\n",
    "        print('error rate ' + str(i) + \":\")\n",
    "        error_rate = float(fn+fp) / total\n",
    "        print(error_rate)\n",
    "\n",
    "        if (p!=0):\n",
    "            recall = float(tp)/p\n",
    "            print('tp-rate/recall/sensitivity ' + str(i) + \":\")\n",
    "            print(recall)\n",
    "\n",
    "        if (n!=0):\n",
    "            fp_rate = float(fp)/n\n",
    "            print('fp-rate ' + str(i) + \":\")\n",
    "            print(fp_rate)\n",
    "\n",
    "        if (n!=0):\n",
    "            specificity = float(tn)/n\n",
    "            print('specificity ' + str(i) + \":\")\n",
    "            print(specificity)\n",
    "\n",
    "        if (p_acc!=0):\n",
    "            precision = float(tp)/p_acc\n",
    "            print('precision ' + str(i) + \":\")\n",
    "            print(precision)\n",
    "\n",
    "        if (n!=0):\n",
    "            accuracy = float(tp + tn)/total\n",
    "            print('accuracy ' + str(i) + \":\")\n",
    "            print(accuracy)\n",
    "\n",
    "        if (precision+recall != 0):\n",
    "            f_measure = 2 * float(precision * recall) / (precision + recall)\n",
    "            print('F-measure ' + str(i) + \":\")\n",
    "            print(f_measure)\n",
    "\n",
    "        balanced_accuracy = float(recall + specificity) / 2\n",
    "        print('Balanced accuracy ' + str(i) + \":\")\n",
    "        print(balanced_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Skema 10-fold cross validation, dan menampilkan kinerjanya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLP Model with k-fold: \n",
      "TRAIN: --------\n",
      "VALIDATION: --------\n",
      "0.38016873387297423  vs  0\n",
      "0.38252682291285983  vs  0\n",
      "0.3822899855068668  vs  0\n",
      "0.3827907901347431  vs  0\n",
      "0.38002497093798365  vs  0\n",
      "0.37788102177299154  vs  0\n",
      "0.3816742417546446  vs  0\n",
      "0.3807077784193193  vs  0\n",
      "0.3841381322225183  vs  0\n",
      "0.3820981867059548  vs  0\n",
      "0.37872492135870367  vs  0\n",
      "0.38110637113441326  vs  0\n",
      "0.3827873570090221  vs  0\n",
      "0.38421655559709544  vs  0\n",
      "0.37699170228639634  vs  0\n",
      "correct: 15 out of  15\n",
      "TRAIN: --------\n",
      "VALIDATION: --------\n",
      "0.37534409847406464  vs  0\n",
      "0.37747590384798985  vs  0\n",
      "0.37954746221655433  vs  0\n",
      "0.37753762274737684  vs  0\n",
      "0.37850236540829896  vs  0\n",
      "0.3795449585029796  vs  0\n",
      "0.37881567846185155  vs  0\n",
      "0.38000999920311157  vs  0\n",
      "0.38032250792229844  vs  0\n",
      "0.38075128469685093  vs  0\n",
      "0.3817465680559533  vs  0\n",
      "0.38014233010213894  vs  0\n",
      "0.3794542436445922  vs  0\n",
      "0.37977721204217113  vs  0\n",
      "0.38156567908414074  vs  0\n",
      "correct: 15 out of  15\n",
      "TRAIN: --------\n",
      "VALIDATION: --------\n",
      "0.38169000508406065  vs  0\n",
      "0.37878011644102894  vs  0\n",
      "0.3782735292078657  vs  0\n",
      "0.37699935564373094  vs  0\n",
      "0.3815348874359577  vs  0\n",
      "0.3806935415078451  vs  0\n",
      "0.37854225293200067  vs  0\n",
      "0.3815348874359577  vs  0\n",
      "0.3831151023870201  vs  0\n",
      "0.3800164822706856  vs  0\n",
      "0.379820861647189  vs  0\n",
      "0.3844033598157962  vs  0\n",
      "0.38260524512453525  vs  0\n",
      "0.37938505204458983  vs  0\n",
      "0.37887803608737747  vs  0\n",
      "correct: 15 out of  15\n",
      "TRAIN: --------\n",
      "VALIDATION: --------\n",
      "0.38048054070602816  vs  0\n",
      "0.37737211532894177  vs  0\n",
      "0.3806232860958445  vs  0\n",
      "0.3768269470808167  vs  0\n",
      "0.37886608240704206  vs  0\n",
      "0.376987065485104  vs  1\n",
      "0.37881069668062234  vs  1\n",
      "0.37794088212804683  vs  1\n",
      "0.3838339167403224  vs  1\n",
      "0.37970560326038055  vs  1\n",
      "0.3823652696752074  vs  1\n",
      "0.37924146527260383  vs  1\n",
      "0.3846729537439836  vs  1\n",
      "0.3789681161974789  vs  1\n",
      "0.3836960619494344  vs  1\n",
      "correct: 5 out of  15\n",
      "TRAIN: --------\n",
      "VALIDATION: --------\n",
      "0.38461339604394673  vs  1\n",
      "0.37821122087021997  vs  1\n",
      "0.3807205983965975  vs  1\n",
      "0.3782961004855614  vs  1\n",
      "0.37936200909495016  vs  1\n",
      "0.3756662104258197  vs  1\n",
      "0.3794030880138342  vs  1\n",
      "0.37998924979659043  vs  1\n",
      "0.3797016666046547  vs  1\n",
      "0.38100445437280794  vs  1\n",
      "0.3776803512763243  vs  1\n",
      "0.3782485854913474  vs  1\n",
      "0.37877790406223877  vs  1\n",
      "0.3788323460496859  vs  1\n",
      "0.37719484619167637  vs  1\n",
      "correct: 0 out of  15\n",
      "TRAIN: --------\n",
      "VALIDATION: --------\n",
      "0.38220617193910056  vs  1\n",
      "0.38372184527767156  vs  1\n",
      "0.38397374765997677  vs  1\n",
      "0.38433759855278543  vs  1\n",
      "0.3831169467223997  vs  1\n",
      "0.38534870152025485  vs  1\n",
      "0.38498156153619384  vs  1\n",
      "0.38371028939040186  vs  1\n",
      "0.38701894306500406  vs  1\n",
      "0.38527527346395213  vs  1\n",
      "0.3823241795980818  vs  1\n",
      "0.38250357697993104  vs  1\n",
      "0.38576794007416226  vs  1\n",
      "0.3835171533423976  vs  1\n",
      "0.38564986833516357  vs  1\n",
      "correct: 0 out of  15\n",
      "TRAIN: --------\n",
      "VALIDATION: --------\n",
      "0.34177083707114936  vs  1\n",
      "0.33838473654592444  vs  1\n",
      "0.3405789515448071  vs  1\n",
      "0.34445325232541685  vs  1\n",
      "0.34097575628307036  vs  1\n",
      "0.3397105275000214  vs  1\n",
      "0.3399815627447152  vs  1\n",
      "0.33831184911250584  vs  1\n",
      "0.34323798994557886  vs  1\n",
      "0.3402708286258588  vs  1\n",
      "0.3368576224360928  vs  1\n",
      "0.3402801105957332  vs  1\n",
      "0.33535942335285074  vs  1\n",
      "0.33817467092957926  vs  1\n",
      "0.33714531666801223  vs  1\n",
      "correct: 0 out of  15\n",
      "TRAIN: --------\n",
      "VALIDATION: --------\n",
      "0.25349646180141094  vs  1\n",
      "0.2648808740572035  vs  1\n",
      "0.255009373658635  vs  1\n",
      "0.2579736509751431  vs  1\n",
      "0.252934299173441  vs  1\n",
      "0.25695872089286664  vs  1\n",
      "0.2585389338464372  vs  1\n",
      "0.256239092158927  vs  1\n",
      "0.2612926299579916  vs  1\n",
      "0.2594300613209974  vs  1\n",
      "0.256664889078941  vs  1\n",
      "0.25742445538141795  vs  1\n",
      "0.25136624818488573  vs  1\n",
      "0.2537482239118472  vs  1\n",
      "0.2620511330372124  vs  1\n",
      "correct: 0 out of  15\n",
      "TRAIN: --------\n",
      "VALIDATION: --------\n",
      "0.2583418109162888  vs  1\n",
      "0.2638045265727668  vs  1\n",
      "0.2570666824103812  vs  1\n",
      "0.26208575342088175  vs  1\n",
      "0.2586194917309374  vs  1\n",
      "0.257575350528262  vs  1\n",
      "0.26212662764596495  vs  1\n",
      "0.26172024389301646  vs  1\n",
      "0.2609466823054256  vs  1\n",
      "0.2582836808384926  vs  1\n",
      "0.2581074437667104  vs  1\n",
      "0.25425945817665885  vs  1\n",
      "0.26091537298465955  vs  1\n",
      "0.26174309022183156  vs  1\n",
      "0.26267858429779267  vs  1\n",
      "correct: 0 out of  15\n",
      "TRAIN: --------\n",
      "VALIDATION: --------\n",
      "0.25667067691312206  vs  1\n",
      "0.2582423998041974  vs  1\n",
      "0.25979209291334043  vs  1\n",
      "0.26172675481711893  vs  1\n",
      "0.2585750765393599  vs  1\n",
      "0.25857415963428004  vs  1\n",
      "0.25865711068592806  vs  1\n",
      "0.263131612082622  vs  1\n",
      "0.25783206112553253  vs  1\n",
      "0.257654828891244  vs  1\n",
      "0.2593826678218833  vs  1\n",
      "0.26292250046746746  vs  1\n",
      "0.26006785244382175  vs  1\n",
      "0.25869452019437744  vs  1\n",
      "0.2616759369863031  vs  1\n",
      "correct: 0 out of  15\n",
      "MLP Model total score: 0.33333333333333337\n",
      "Evaluating C45 Model with k-fold: \n",
      "TRAIN: --------\n",
      "=================================================\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      ">attr3\n",
      "    <0.0>\n",
      "        attr1\n",
      "            <0.0>\n",
      "                attr4\n",
      "                    <0.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-setosa)\n",
      "                            <1.0>\n",
      "                                (Iris-setosa)\n",
      "                    <1.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "            <1.0>\n",
      "                attr2\n",
      "                    <0.0>\n",
      "                        (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        attr4\n",
      "                            <0.0>\n",
      "                                (Iris-setosa)\n",
      "                            <1.0>\n",
      "                                (Iris-versicolor)\n",
      "    <1.0>\n",
      "        attr2\n",
      "            <0.0>\n",
      "                attr1\n",
      "                    <1.0>\n",
      "                        attr4\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "            <1.0>\n",
      "                (Iris-virginica)\n",
      "=================================================\n",
      "VALIDATION: --------\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "correct: 15 out of  15\n",
      "TRAIN: --------\n",
      "=================================================\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      ">attr3\n",
      "    <0.0>\n",
      "        attr2\n",
      "            <0.0>\n",
      "                attr4\n",
      "                    <0.0>\n",
      "                        attr1\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "                            <1.0>\n",
      "                                (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        attr1\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "                            <1.0>\n",
      "                                (Iris-versicolor)\n",
      "            <1.0>\n",
      "                attr4\n",
      "                    <0.0>\n",
      "                        (Iris-setosa)\n",
      "                    <1.0>\n",
      "                        (Iris-versicolor)\n",
      "    <1.0>\n",
      "        attr2\n",
      "            <0.0>\n",
      "                attr1\n",
      "                    <0.0>\n",
      "                        attr4\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "                    <1.0>\n",
      "                        attr4\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "            <1.0>\n",
      "                attr1\n",
      "                    <0.0>\n",
      "                        attr4\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "                    <1.0>\n",
      "                        (Iris-virginica)\n",
      "=================================================\n",
      "VALIDATION: --------\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "correct: 15 out of  15\n",
      "TRAIN: --------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      ">attr3\n",
      "    <0.0>\n",
      "        attr1\n",
      "            <0.0>\n",
      "                attr4\n",
      "                    <0.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-setosa)\n",
      "                            <1.0>\n",
      "                                (Iris-setosa)\n",
      "                    <1.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "            <1.0>\n",
      "                attr2\n",
      "                    <0.0>\n",
      "                        (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        attr4\n",
      "                            <0.0>\n",
      "                                (Iris-setosa)\n",
      "                            <1.0>\n",
      "                                (Iris-versicolor)\n",
      "    <1.0>\n",
      "        attr2\n",
      "            <0.0>\n",
      "                attr1\n",
      "                    <1.0>\n",
      "                        attr4\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "            <1.0>\n",
      "                (Iris-virginica)\n",
      "=================================================\n",
      "VALIDATION: --------\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "correct: 15 out of  15\n",
      "TRAIN: --------\n",
      "=================================================\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      ">attr3\n",
      "    <0.0>\n",
      "        attr4\n",
      "            <0.0>\n",
      "                attr2\n",
      "                    <0.0>\n",
      "                        attr1\n",
      "                            <0.0>\n",
      "                                (Iris-setosa)\n",
      "                    <1.0>\n",
      "                        (Iris-setosa)\n",
      "            <1.0>\n",
      "                attr1\n",
      "                    <0.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "                            <1.0>\n",
      "                                (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        (Iris-versicolor)\n",
      "    <1.0>\n",
      "        attr2\n",
      "            <0.0>\n",
      "                attr1\n",
      "                    <0.0>\n",
      "                        attr4\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "                    <1.0>\n",
      "                        attr4\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "            <1.0>\n",
      "                (Iris-virginica)\n",
      "=================================================\n",
      "VALIDATION: --------\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-setosa  vs  Iris-setosa\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-setosa  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "correct: 10 out of  15\n",
      "TRAIN: --------\n",
      "=================================================\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      ">attr3\n",
      "    <0.0>\n",
      "        attr4\n",
      "            <0.0>\n",
      "                attr2\n",
      "                    <0.0>\n",
      "                        attr1\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        (Iris-setosa)\n",
      "            <1.0>\n",
      "                attr1\n",
      "                    <0.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "                            <1.0>\n",
      "                                (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        (Iris-versicolor)\n",
      "    <1.0>\n",
      "        attr2\n",
      "            <0.0>\n",
      "                attr1\n",
      "                    <0.0>\n",
      "                        attr4\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "                    <1.0>\n",
      "                        attr4\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "            <1.0>\n",
      "                attr1\n",
      "                    <0.0>\n",
      "                        (Iris-virginica)\n",
      "                    <1.0>\n",
      "                        attr4\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "=================================================\n",
      "VALIDATION: --------\n",
      "Iris-setosa  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-setosa  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-setosa  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-setosa  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-setosa  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "correct: 2 out of  15\n",
      "TRAIN: --------\n",
      "=================================================\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      ">attr3\n",
      "    <0.0>\n",
      "        attr4\n",
      "            <0.0>\n",
      "                attr2\n",
      "                    <0.0>\n",
      "                        attr1\n",
      "                            <0.0>\n",
      "                                (Iris-setosa)\n",
      "                            <1.0>\n",
      "                                (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        (Iris-setosa)\n",
      "            <1.0>\n",
      "                attr1\n",
      "                    <0.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        (Iris-versicolor)\n",
      "    <1.0>\n",
      "        attr2\n",
      "            <0.0>\n",
      "                attr1\n",
      "                    <1.0>\n",
      "                        attr4\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "            <1.0>\n",
      "                (Iris-virginica)\n",
      "=================================================\n",
      "VALIDATION: --------\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-setosa  vs  Iris-versicolor\n",
      "Iris-setosa  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-versicolor  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-versicolor\n",
      "correct: 8 out of  15\n",
      "TRAIN: --------\n",
      "=================================================\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      ">attr3\n",
      "    <0.0>\n",
      "        attr2\n",
      "            <0.0>\n",
      "                attr4\n",
      "                    <0.0>\n",
      "                        attr1\n",
      "                            <0.0>\n",
      "                                (Iris-setosa)\n",
      "                    <1.0>\n",
      "                        (Iris-versicolor)\n",
      "            <1.0>\n",
      "                (Iris-setosa)\n",
      "    <1.0>\n",
      "        attr4\n",
      "            <0.0>\n",
      "                (Iris-versicolor)\n",
      "            <1.0>\n",
      "                attr1\n",
      "                    <0.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "                    <1.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-virginica)\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "=================================================\n",
      "VALIDATION: --------\n",
      "LOST CAUSE  vs  Iris-versicolor\n",
      "LOST CAUSE  vs  Iris-versicolor\n",
      "LOST CAUSE  vs  Iris-versicolor\n",
      "Iris-setosa  vs  Iris-versicolor\n",
      "LOST CAUSE  vs  Iris-versicolor\n",
      "LOST CAUSE  vs  Iris-versicolor\n",
      "LOST CAUSE  vs  Iris-versicolor\n",
      "LOST CAUSE  vs  Iris-versicolor\n",
      "Iris-setosa  vs  Iris-versicolor\n",
      "LOST CAUSE  vs  Iris-versicolor\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "LOST CAUSE  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "correct: 4 out of  15\n",
      "TRAIN: --------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      ">attr4\n",
      "    <0.0>\n",
      "        attr2\n",
      "            <0.0>\n",
      "                attr1\n",
      "                    <0.0>\n",
      "                        attr3\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        (Iris-versicolor)\n",
      "            <1.0>\n",
      "                (Iris-setosa)\n",
      "    <1.0>\n",
      "        attr3\n",
      "            <0.0>\n",
      "                attr1\n",
      "                    <0.0>\n",
      "                        (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "                            <1.0>\n",
      "                                (Iris-versicolor)\n",
      "            <1.0>\n",
      "                attr2\n",
      "                    <0.0>\n",
      "                        attr1\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "                    <1.0>\n",
      "                        attr1\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "=================================================\n",
      "VALIDATION: --------\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "correct: 15 out of  15\n",
      "TRAIN: --------\n",
      "=================================================\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      ">attr4\n",
      "    <0.0>\n",
      "        attr1\n",
      "            <0.0>\n",
      "                attr2\n",
      "                    <0.0>\n",
      "                        attr3\n",
      "                            <0.0>\n",
      "                                (Iris-setosa)\n",
      "                    <1.0>\n",
      "                        (Iris-setosa)\n",
      "            <1.0>\n",
      "                attr2\n",
      "                    <0.0>\n",
      "                        attr3\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        (Iris-setosa)\n",
      "    <1.0>\n",
      "        attr3\n",
      "            <0.0>\n",
      "                attr1\n",
      "                    <0.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "            <1.0>\n",
      "                attr2\n",
      "                    <0.0>\n",
      "                        attr1\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "                    <1.0>\n",
      "                        (Iris-virginica)\n",
      "=================================================\n",
      "VALIDATION: --------\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-versicolor  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "correct: 14 out of  15\n",
      "TRAIN: --------\n",
      "=================================================\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      ">attr3\n",
      "    <0.0>\n",
      "        attr1\n",
      "            <0.0>\n",
      "                attr4\n",
      "                    <0.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-setosa)\n",
      "                            <1.0>\n",
      "                                (Iris-setosa)\n",
      "                    <1.0>\n",
      "                        attr2\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "            <1.0>\n",
      "                attr2\n",
      "                    <0.0>\n",
      "                        attr4\n",
      "                            <0.0>\n",
      "                                (Iris-versicolor)\n",
      "                            <1.0>\n",
      "                                (Iris-versicolor)\n",
      "                    <1.0>\n",
      "                        (Iris-setosa)\n",
      "    <1.0>\n",
      "        attr2\n",
      "            <0.0>\n",
      "                attr1\n",
      "                    <1.0>\n",
      "                        attr4\n",
      "                            <1.0>\n",
      "                                (Iris-virginica)\n",
      "            <1.0>\n",
      "                (Iris-virginica)\n",
      "=================================================\n",
      "VALIDATION: --------\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-versicolor  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "Iris-virginica  vs  Iris-virginica\n",
      "correct: 14 out of  15\n",
      "MLP Model total score: 0.7466666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from MyC45 import MyTree, handleContinuousAttribute, resetThresholdDict, printThresholdDict\n",
    "import MultiLayerPerceptronAS\n",
    "\n",
    "def kFold(nFold, # how many folds\n",
    "         dataset, # dataset to be kFold-ed\n",
    "         ):\n",
    "    split = len(dataset) // nFold\n",
    "    result = []\n",
    "    start_idx = 0\n",
    "    for i in range(nFold):\n",
    "        indices = list(range(0,start_idx)) + list(range(start_idx+split,len(dataset)))\n",
    "        train = dataset[indices]\n",
    "        test = dataset[start_idx:start_idx+split]\n",
    "        result.append( (train,test) ) # tuple of ( train dataset, test dataset)\n",
    "        start_idx += split\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "irisDataMLP = []\n",
    "with open('irisMLP.csv') as f:\n",
    "    freader = csv.reader(f, delimiter=',')\n",
    "    for row in freader:\n",
    "        irisDataMLP.append(row)\n",
    "irisDataMLP = np.array(irisDataMLP)\n",
    "\n",
    "# print(irisDataMLP)\n",
    "\n",
    "# kf = KFold(n_splits=10, shuffle=False, random_state=1)\n",
    "attrs=['attr1', 'attr2', 'attr3', 'attr4', 'target']\n",
    "\n",
    "nFold = 10\n",
    "MLPresult = kFold(nFold, irisDataMLP)\n",
    "\n",
    "# Evaluate for MLP:\n",
    "print(\"Evaluating MLP Model with k-fold: \")\n",
    "\n",
    "totalScore = 0\n",
    "for train, test in MLPresult:\n",
    "    print(\"TRAIN: --------\")\n",
    "    with open ('dummy.csv', mode='w', newline=\"\") as f:\n",
    "        fwriter = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in train: # train dataset\n",
    "            fwriter.writerow(row)\n",
    "    # ANN:\n",
    "    data = pd.read_csv(\"dummy.csv\")\n",
    "    mlp2 = MultiLayerPerceptronAS.callMLP(32, data)\n",
    "\n",
    "    print(\"VALIDATION: --------\")\n",
    "    correct = 0\n",
    "    for row in test: # test dataset\n",
    "        values = []\n",
    "        for val, attr in zip(row[:-1], attrs[:-1]):\n",
    "            values.append(float(val))\n",
    "        # print(values)\n",
    "        prediction = float(mlp2.estimate(values)[0])\n",
    "        print(prediction, \" vs \", row[-1])\n",
    "        # threshold: 0.5\n",
    "        if abs(prediction - float(row[-1])) < 0.5:\n",
    "            correct+=1\n",
    "    print(\"correct:\", correct, \"out of \", len(test))\n",
    "    totalScore += correct / float(len(test))\n",
    "\n",
    "print(\"MLP Model total score:\", totalScore/nFold)\n",
    "\n",
    "# Evaluate for C45:\n",
    "irisData = []\n",
    "with open('iris.csv') as f:\n",
    "    freader = csv.reader(f, delimiter=',')\n",
    "    for row in freader:\n",
    "        irisData.append(row)\n",
    "irisData = np.array(irisData)\n",
    "\n",
    "C45result = kFold(nFold, irisData)\n",
    "# print(C45result)\n",
    "print(\"Evaluating C45 Model with k-fold: \")\n",
    "\n",
    "totalScore = 0\n",
    "# idx = 0\n",
    "for train, test in C45result:\n",
    "    # print(idx)\n",
    "    # idx+=1\n",
    "    print(\"TRAIN: --------\")\n",
    "    # trainn, testt = C45result[7]\n",
    "    with open ('dummy.csv', mode='w') as f:\n",
    "        fwriter = csv.writer(f)\n",
    "        for row in train:\n",
    "            fwriter.writerow(row)\n",
    "\n",
    "    data = pd.read_csv(\"dummy.csv\", header=None, names=attrs)\n",
    "    training_dataset = handleContinuousAttribute(data)\n",
    "    t2 = MyTree(_targetAttribute = 'target')\n",
    "    print(\"=================================================\")\n",
    "    t2.buildTreeInit(trainingSet = training_dataset)\n",
    "    t2.printTree()\n",
    "    print(\"=================================================\")\n",
    "\n",
    "    print(\"VALIDATION: --------\")\n",
    "    #print(irisData[test])\n",
    "    correct = 0\n",
    "    for row in test:\n",
    "        values = {}\n",
    "        for val, attr in zip(row[:-1], attrs[:-1]):\n",
    "            values[attr] = float(val)\n",
    "        # print(values)\n",
    "        prediction = t.predict(values)\n",
    "        print(prediction, \" vs \", row[-1])\n",
    "        if prediction == row[-1]:\n",
    "            correct+=1\n",
    "    print(\"correct:\", correct, \"out of \", len(test))\n",
    "    totalScore += correct / float(len(test))\n",
    "    # reset threshold dict:\n",
    "    resetThresholdDict()\n",
    "\n",
    "print(\"C45 Model total score:\", totalScore/nFold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Menyimpan (save) model pembelajaran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Entropy not 0 but already ran out attributes\n",
      "Model saved\n",
      "Model saved\n",
      "Model saved\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mlp2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3494a5c48b5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"split_mlp.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"myc45_model.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mlp_kfold.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"myc45_model_kfold.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mlp2' is not defined"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "data = pd.read_csv(\"iris.csv\", header=None, names=['attr1', 'attr2', 'attr3', 'attr4', 'target'])\n",
    "data = MyC45.handleContinuousAttribute(data)\n",
    "\n",
    "# Learning\n",
    "t = MyC45.MyTree(_targetAttribute = 'target')\n",
    "t.buildTreeInit(trainingSet = data)\n",
    "\n",
    "# Save model\n",
    "em.saveModel(tree, \"split_tree.pickle\")\n",
    "em.saveModel(mlp, \"split_mlp.pickle\")\n",
    "em.saveModel(t, \"myc45_model.pickle\")\n",
    "em.saveModel(mlp2, \"mlp_kfold.pickle\")\n",
    "em.saveModel(t2,\"myc45_model_kfold.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Membaca (load) model pembelajaran"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load model\n",
    "t_new = em.loadModel(\"myc45_model.pickle\")\n",
    "split_tree_new = em.loadModel(\"split_tree.pickle\")\n",
    "split_mlp_new = em.loadModel(\"split_mlp.pickle\")\n",
    "mlp2_kfold_new = em.loadModel(\"mlp_kfold.pickle\")\n",
    "t2_kfold_new = em.loadModel(\"myc45_model_kfold.pickle\")\n",
    "\n",
    "confusion_matrixMLP = np.zeros((3, 3))\n",
    "for i in range(len(test_dataMLP)):\n",
    "    test = list(test_dataMLP.iloc[i,:-mlp.outputs])\n",
    "    target = list(test_dataMLP.iloc[i,mlp.inputs:])\n",
    "    estimate = split_mlp_new.estimate(test)\n",
    "    # print(estimate)\n",
    "    for i in range(len(estimate)):\n",
    "        estimate[i] = round(estimate[i])\n",
    "    # print(estimate)\n",
    "    # print(target)\n",
    "    row = -1\n",
    "    if (target == [0, 0]):\n",
    "        row = 0\n",
    "    elif (target == [0, 1]):\n",
    "        row = 1\n",
    "    elif (target == [1, 1]):\n",
    "        row = 2\n",
    "    column = -1\n",
    "    if (estimate == [0, 0]):\n",
    "        column = 0\n",
    "    elif (estimate == [0, 1]):\n",
    "        column = 1\n",
    "    elif (estimate == [1, 1]):\n",
    "        column = 2\n",
    "    if (column >= 0 and row >= 0):\n",
    "        confusion_matrixMLP[row][column] += 1\n",
    "print(\"MLP confusion matrix:\")\n",
    "print(confusion_matrixMLP)\n",
    "\n",
    "confusion_matrixDTL = np.zeros((3, 3))\n",
    "# tree.printTree()\n",
    "for i in range(len(test_dataDTL)):\n",
    "    test = test_dataDTL.iloc[i]\n",
    "    target = test[\"target\"]\n",
    "    test = test.to_dict()\n",
    "    for key in test:\n",
    "        test[key] = str(test[key])\n",
    "    # print(test)\n",
    "    estimate = split_tree_new.predict(test)\n",
    "    # print(estimate)\n",
    "    row = -1\n",
    "    row = int(target)\n",
    "    column = -1\n",
    "    column = int(estimate)\n",
    "    if (column >= 0 and row >= 0):\n",
    "        confusion_matrixDTL[row][column] += 1\n",
    "print(\"DTL confusion matrix:\")\n",
    "print(confusion_matrixDTL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Klasifikasi menggunakan model pada poin IV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# print(t_new.predict({}))\n",
    "# ANN\n",
    "values = [1.2, 3.2, 9.9, 4.3]\n",
    "prediction = mlp2_kfold_new.estimate(values)\n",
    "# DTL\n",
    "t2_kfold_new = MyC45.MyTree(_targetAttribute = 'target')\n",
    "t2_kfold_new.buildTreeInit(trainingSet = data)\n",
    "values = {\n",
    "   'attr1' : 1.2,\n",
    "   'attr2' : 2.3,\n",
    "   'attr3' : 9.9,\n",
    "   'attr4' : 3.4\n",
    "}\n",
    "prediction = t.predict(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Analisis hasil eksperimen poin I dan II\n",
    "    \n",
    "### Split train 90% dan test 10%\n",
    "    Pada eksperimen point I Skema split train 90% dan test 10% bagian MLP, menghasilkan confusion matrix<br>\n",
    "\n",
    "[5 0 0<br>\n",
    "0 6 0<br>\n",
    "0 3 1]<br>\n",
    "   \n",
    "    dimana pada row 0 dan row 1, model kami berhasil memprediksi seluruh kasus dengan benar sedangkan pada row 2, model kami hanya memprediksi 1 dari 4 saja yang benar. hal ini menunjukkan bahwa ada kasus dimana model kami mengembalikan false positive.\n",
    "    \n",
    "    Lalu pada training DTL dengan Skema I model kami menghasilkan confusion matrix sebagai berikut <br>\n",
    "[6 0 0<br>\n",
    "1 3 1<br>\n",
    "0 0 4]<br>\n",
    "\n",
    "    Pada row 0 model kami berhasil memprediksi true positive seluruhnya. lalu pada row 1, model kami berhasil memprediksi benar 3 dari 5 namun untuk sisa 2nya salah. Selain itu pada row 2, model kami berhasil memprediksi true positive seluruh kasus. Salah satu faktor penyebab kesalahan dalam memprediksi data adalah faktor shuffle dalam training, kurangnya iterasi, overfit data, kurang spesifiknya data yang tersedia, atau bisa juga kurang banyaknya data. Untuk MLP, beberapa faktor lainnya adalah karena kurangnya layer pada hidden node sehingga mengurangi akurasi dan juga faktor batch size yang tidak seimbang.\n",
    "\n",
    "### K-Fold Cross Validation\n",
    "    K-Fold Cross-Validation adalah resampling procedure yang digunakan untuk evaluasi model ML ketika dataset yang tersedia sangat sedikit. Prosedur ini memiliki parameter tunggal k yang menandakan seberapa banyak grup sample data yang diberikan akan terbagi. \n",
    "\n",
    "    Untuk kasus ini, k = 10 (ten fold cross validation). 10 dipilih karena menurut penelitian telah dibuktikan k yang bernilai 10 memiliki probabilitas untuk menghasilkan evaluasi model ML yang memiliki bias rendah dan variansi yang minimal.\n",
    "\n",
    "#### Prosedur yang dilakukan untuk k-Fold:\n",
    "1.  Sebisa mungkin split dataset original menjadi group sebanyak k\n",
    "2. Untuk setiap group k:\n",
    "     a. Ambil satu partisi sebagai validation dataset\n",
    "     b. dataset yang tersisa dijadikan training dataset\n",
    "     c. gunakan dataset training untuk membangun dan melatih model ML\n",
    "     d. menghitung skor evaluasi dengan validation dataset dan buang model tersebut\n",
    "3. Tarik kesimpulan /rata-rata skor dari model ML menurut setiap skor dari tahap evaluasi\n",
    "\n",
    "#### Constraint:\n",
    "1. Setiap group harus unique, setiap observasi (row) pada dataset hanya boleh menjadi bagian dari validation set hanya 1x saja\n",
    "2. Suatu observasi dapat menjadi bagian dari training set atau validation set pada suatu iterasi, namun tidak kedua-duanya sekaligus dalam satu iterasi\n",
    "\n",
    "|Iteration|Training set obsevations|Testing set observations|\n",
    "|---------|------------------------|------------------------|\n",
    "|1|[ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]|[0 1 2 3 4]|\n",
    "|2|[ 0  1  2  3  4 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]|[5 6 7 8 9]|\n",
    "|3|[ 0  1  2  3  4  5  6  7  8  9 15 16 17 18 19 20 21 22 23 24]|[10 11 12 13 14]|\n",
    "|4|[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 20 21 22 23 24]|[15 16 17 18 19]|\n",
    "|5|[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]|[20 21 22 23 24]|\n",
    "    \n",
    "    \n",
    "### Kesimpulan\n",
    "    Jika dibandingkan dengan 10 fold Cross Validation, tentunya ada kelemahan dan kelebihan dari skema ke-2 ini. Dimana untuk Skema 10 Fold Cross Validation, training dilakukan 10 kali dengan men-switch training data dan test data yang ada. Dari sini, dapat kita temukan pasangan training data dan test data yang memiliki accuracy paling besar dari 10 kali iterasi pelatihan model. \n",
    "\n",
    "    Kelemahan dari 10 fold Cross Validation tentunya terletak pada waktu yang diberikan untuk melatih modelnya. Dimana jika kita menggunakan 10 Fold Cross Validation, tentunya pelatihan model akan lebih lama namun akan mendapatkan model yang lebih akurat. Kenapa 10? karena nilai 10 adalah nilai yang telah ditemukan melalui eksperimen untuk secara umum menghasilkan estimasi keterampilan model dengan bias rendah dan varian yang tidak terlalu bervariasi."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
